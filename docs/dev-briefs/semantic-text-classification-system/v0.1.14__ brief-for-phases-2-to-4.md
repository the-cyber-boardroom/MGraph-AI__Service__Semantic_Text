# Technical Brief: Semantic Text Classification System - Levels 2-6

**Project**: MGraph AI Service - Semantic Text Classification  
**Phase**: Levels 2-6 (Post Level 1 Implementation)  
**Date**: November 2025  
**Status**: Planning Phase  
**Dependencies**: Level 1 must be deployed and operational

---

## Executive Summary

This technical brief outlines the development roadmap for Levels 2-6 of the Semantic Text Classification system. Each level progressively adds semantic intelligence capabilities, culminating in a full semantic graph generation system. All levels are designed to work with **simulated/random engines** initially, with the architecture ready for LLM integration as a final step.

**Key Principle**: Build and validate the entire architecture with fast, deterministic engines (random, hash-based, pre-configured) BEFORE adding the complexity and latency of LLMs.

---

## Architecture Philosophy

### Core Design Principles

1. **Progressive Complexity**: Each level adds one major capability
2. **Independent Deployment**: Each level can be deployed separately
3. **No Rework**: Each level builds cleanly on previous levels
4. **Engine Agnostic**: All levels work with any classification engine
5. **Cache Ready**: All levels designed for aggressive caching
6. **Type Safe**: Full Type_Safe validation at all boundaries
7. **Test Driven**: 100% test coverage at each level

### Classification Engine Strategy

```
Development Phases:
┌─────────────────────────────────────────────────────────────┐
│ Phase 1: Architecture (Levels 1-6)                          │
│   - Use Random/Hash-based engines                           │
│   - Validate architecture scales                            │
│   - Measure performance baseline                            │
│   - Build complete feature set                              │
│   Duration: 2-3 weeks                                        │
└─────────────────────────────────────────────────────────────┘
                         ↓
┌─────────────────────────────────────────────────────────────┐
│ Phase 2: LLM Integration (After all levels work)            │
│   - Swap Random engine for LLM engines                      │
│   - No architectural changes needed                         │
│   - Focus on prompt engineering                             │
│   - Optimize LLM performance                                │
│   Duration: 1-2 weeks                                        │
└─────────────────────────────────────────────────────────────┘
```

**Why This Order?**
- Validates architecture is sound before adding LLM complexity
- Measures true performance ceiling (no LLM latency)
- Enables parallel development (architecture team + prompt engineering team)
- Reduces debugging complexity (no LLM variability during development)
- Allows experimentation with visualization and UX at full speed

---

## Level 2: Multiple Criteria Classification

### Overview
Extends Level 1 to support **multiple simultaneous criteria** with AND/OR filtering logic.

### New Capabilities
1. Classify by multiple criteria simultaneously (positivity + negativity + toxicity + bias + urgency)
2. Filter with complex boolean logic (AND/OR operations)
3. Aggregate scores across multiple criteria
4. Compare relative importance of different criteria

### Technical Specifications

#### New Schemas
```python
# Schema__Classification__Multi_Criteria_Request.py
class Schema__Classification__Multi_Criteria_Request(Type_Safe):
    hash_mapping              : Dict[Safe_Str__Hash, str]
    classification_criterias  : List[Enum__Text__Classification__Criteria]  # Multiple criteria
    aggregate_mode            : Enum__Classification__Aggregate_Mode = AVERAGE  # How to combine scores

# Schema__Classification__Multi_Criteria_Response.py
class Schema__Classification__Multi_Criteria_Response(Type_Safe):
    hash_ratings              : Dict[Safe_Str__Hash, Dict[Enum__Text__Classification__Criteria, Safe_Float__Text__Classification]]
    aggregate_ratings         : Dict[Safe_Str__Hash, Safe_Float__Text__Classification]  # Combined score
    classification_criterias  : List[Enum__Text__Classification__Criteria]
    aggregate_mode            : Enum__Classification__Aggregate_Mode
    total_hashes              : Safe_UInt
    success                   : bool

# Schema__Classification__Multi_Filter_Request.py
class Schema__Classification__Multi_Filter_Request(Type_Safe):
    hash_mapping              : Dict[Safe_Str__Hash, str]
    filter_conditions         : List[Schema__Filter_Condition]  # Multiple conditions
    boolean_operator          : Enum__Boolean_Operator = AND     # How to combine conditions
    output_mode               : Enum__Classification__Output_Mode
```

#### New Enums
```python
# Enum__Classification__Aggregate_Mode.py
class Enum__Classification__Aggregate_Mode(str, Enum):
    AVERAGE    = 'average'     # Mean of all criteria
    WEIGHTED   = 'weighted'    # Weighted average (requires weights)
    MIN        = 'min'         # Lowest score across criteria
    MAX        = 'max'         # Highest score across criteria
    PRODUCT    = 'product'     # Multiply all scores

# Enum__Boolean_Operator.py
class Enum__Boolean_Operator(str, Enum):
    AND = 'and'  # All conditions must pass
    OR  = 'or'   # Any condition must pass
```

#### New Services
```python
# Classification__Multi_Criteria__Service.py
class Classification__Multi_Criteria__Service(Type_Safe):
    classification_filter_service : Classification__Filter__Service
    
    def classify_multi_criteria(request) -> Response:
        # Classify by each criterion
        # Aggregate scores based on aggregate_mode
        # Return comprehensive ratings
    
    def filter_multi_criteria(request) -> Response:
        # Classify by all criteria
        # Apply each filter condition
        # Combine with boolean operator (AND/OR)
        # Return filtered results
    
    def _aggregate_scores(ratings, mode, weights=None) -> float:
        # Combine multiple criterion scores into single value
```

#### New Routes
```python
# Extend Routes__Semantic_Classification.py
POST /semantic-classification/multi/rate
  → Rate hashes by multiple criteria simultaneously

POST /semantic-classification/multi/filter
  → Filter with complex boolean conditions

POST /semantic-classification/multi/aggregate
  → Get aggregate scores across criteria
```

### API Examples

#### Rate Multiple Criteria
```json
POST /semantic-classification/multi/rate
{
  "hash_mapping": {
    "abc1234567": "Great product, highly recommend!",
    "def1234567": "Terrible experience, very disappointed."
  },
  "classification_criterias": ["positivity", "negativity", "urgency"],
  "aggregate_mode": "average"
}

Response:
{
  "hash_ratings": {
    "abc1234567": {
      "positivity": 0.9,
      "negativity": 0.1,
      "urgency": 0.3
    },
    "def1234567": {
      "positivity": 0.2,
      "negativity": 0.8,
      "urgency": 0.6
    }
  },
  "aggregate_ratings": {
    "abc1234567": 0.43,
    "def1234567": 0.53
  }
}
```

#### Filter with AND Logic
```json
POST /semantic-classification/multi/filter
{
  "hash_mapping": {...},
  "filter_conditions": [
    {"criteria": "positivity", "mode": "above", "threshold": 0.7},
    {"criteria": "urgency", "mode": "below", "threshold": 0.5}
  ],
  "boolean_operator": "and",
  "output_mode": "full-ratings"
}

Response:
{
  "filtered_hashes": ["abc1234567"],
  "filtered_count": 1,
  "conditions_met": {
    "abc1234567": ["positivity:above:0.7", "urgency:below:0.5"]
  }
}
```

### Implementation Estimate
- **New Files**: 6 files (3 schemas, 1 service, 2 enums)
- **Modified Files**: 1 file (Routes__Semantic_Classification.py)
- **Test Files**: 6 test files
- **Lines of Code**: ~400 production, ~600 test
- **Development Time**: 2-3 days
- **Testing Time**: 1 day
- **Total**: 3-4 days

### Dependencies
- ✅ Level 1 operational
- ✅ Existing Enum__Text__Classification__Criteria (has 5 criteria already)
- ✅ Semantic_Text__Service (handles all 5 criteria)

---

## Level 3: Topic Classification

### Overview
Assigns **predefined topics** (20-30 categories) to each hash, enabling topic-based filtering and analysis.

### New Capabilities
1. Classify text into 20-30 predefined topics
2. Filter by single or multiple topics
3. Get topic distribution across hash mapping
4. Find most common topics in dataset

### Technical Specifications

#### New Enums
```python
# Enum__Classification__Topic.py
class Enum__Classification__Topic(str, Enum):
    # Technology (5 topics)
    TECHNOLOGY_SOFTWARE      = 'technology-software'
    TECHNOLOGY_HARDWARE      = 'technology-hardware'
    TECHNOLOGY_AI_ML         = 'technology-ai-ml'
    TECHNOLOGY_CYBERSECURITY = 'technology-cybersecurity'
    TECHNOLOGY_DATA          = 'technology-data'
    
    # Business (5 topics)
    BUSINESS_FINANCE         = 'business-finance'
    BUSINESS_MARKETING       = 'business-marketing'
    BUSINESS_SALES           = 'business-sales'
    BUSINESS_STRATEGY        = 'business-strategy'
    BUSINESS_OPERATIONS      = 'business-operations'
    
    # Health (3 topics)
    HEALTH_MEDICAL           = 'health-medical'
    HEALTH_WELLNESS          = 'health-wellness'
    HEALTH_MENTAL            = 'health-mental'
    
    # Education (3 topics)
    EDUCATION_ACADEMIC       = 'education-academic'
    EDUCATION_TRAINING       = 'education-training'
    EDUCATION_RESEARCH       = 'education-research'
    
    # Entertainment (3 topics)
    ENTERTAINMENT_MEDIA      = 'entertainment-media'
    ENTERTAINMENT_GAMING     = 'entertainment-gaming'
    ENTERTAINMENT_SPORTS     = 'entertainment-sports'
    
    # Legal (2 topics)
    LEGAL_COMPLIANCE         = 'legal-compliance'
    LEGAL_CONTRACTS          = 'legal-contracts'
    
    # Communication (3 topics)
    COMMUNICATION_EMAIL      = 'communication-email'
    COMMUNICATION_CHAT       = 'communication-chat'
    COMMUNICATION_FORMAL     = 'communication-formal'
    
    # Sentiment (3 topics)
    SENTIMENT_POSITIVE       = 'sentiment-positive'
    SENTIMENT_NEGATIVE       = 'sentiment-negative'
    SENTIMENT_NEUTRAL        = 'sentiment-neutral'
    
    # Other
    GENERAL                  = 'general'
    UNKNOWN                  = 'unknown'
    
    # Total: 30 topics
```

#### New Schemas
```python
# Schema__Classification__Topics_Request.py
class Schema__Classification__Topics_Request(Type_Safe):
    hash_mapping          : Dict[Safe_Str__Hash, str]
    max_topics_per_hash   : Safe_UInt = Safe_UInt(3)  # Top N topics per hash
    min_confidence        : Safe_Float = Safe_Float(0.1)  # Minimum confidence threshold

# Schema__Classification__Topics_Response.py
class Schema__Classification__Topics_Response(Type_Safe):
    hash_topics           : Dict[Safe_Str__Hash, List[Tuple[Enum__Classification__Topic, Safe_Float]]]  # Hash → [(topic, confidence), ...]
    topic_distribution    : Dict[Enum__Classification__Topic, Safe_UInt]  # Topic → count
    total_hashes          : Safe_UInt
    success               : bool

# Schema__Classification__Topics_Filter_Request.py
class Schema__Classification__Topics_Filter_Request(Type_Safe):
    hash_mapping          : Dict[Safe_Str__Hash, str]
    topics                : List[Enum__Classification__Topic]  # Topics to filter by
    match_mode            : Enum__Topic_Match_Mode = ANY  # ANY or ALL
    min_confidence        : Safe_Float = Safe_Float(0.5)
    output_mode           : Enum__Classification__Output_Mode
```

#### New Services
```python
# Classification__Topics__Service.py
class Classification__Topics__Service(Type_Safe):
    semantic_text_service : Semantic_Text__Service
    
    def classify_topics(request) -> Response:
        # Classify each hash into topics
        # Return top N topics per hash
        # Generate topic distribution
    
    def filter_by_topics(request) -> Response:
        # Classify all hashes
        # Filter by matching topics
        # Apply match_mode (ANY/ALL)
        # Return filtered results
    
    def get_topic_distribution(hash_mapping) -> Dict:
        # Analyze topic frequency across all hashes
    
    def _assign_topics_random(text, max_topics) -> List[Tuple]:
        # Random topic assignment (initial engine)
        # Later: replace with LLM-based classification
```

#### New Routes
```python
# Routes__Semantic_Classification__Topics.py
POST /semantic-classification/topics/classify
  → Classify hashes into topics

POST /semantic-classification/topics/filter
  → Filter by topics

GET /semantic-classification/topics/list
  → Get all available topics

POST /semantic-classification/topics/distribution
  → Get topic distribution analysis
```

### API Examples

#### Classify Topics
```json
POST /semantic-classification/topics/classify
{
  "hash_mapping": {
    "abc1234567": "Our new machine learning model improves accuracy by 15%"
  },
  "max_topics_per_hash": 3,
  "min_confidence": 0.2
}

Response:
{
  "hash_topics": {
    "abc1234567": [
      ["technology-ai-ml", 0.85],
      ["technology-data", 0.62],
      ["business-strategy", 0.31]
    ]
  },
  "topic_distribution": {
    "technology-ai-ml": 1,
    "technology-data": 1,
    "business-strategy": 1
  }
}
```

#### Filter by Topics
```json
POST /semantic-classification/topics/filter
{
  "hash_mapping": {...},
  "topics": ["technology-ai-ml", "technology-data"],
  "match_mode": "any",
  "min_confidence": 0.5,
  "output_mode": "hashes-with-text"
}

Response:
{
  "filtered_hashes": ["abc1234567", "def1234567"],
  "filtered_with_text": {...},
  "filtered_count": 2,
  "topic_matches": {
    "abc1234567": ["technology-ai-ml"],
    "def1234567": ["technology-data"]
  }
}
```

### Topic Assignment Engine Strategy

#### Phase 1: Random Engine (Initial Development)
```python
class Semantic_Text__Engine__Topics_Random:
    def assign_topics(text, max_topics):
        # Randomly select 1-3 topics
        # Assign random confidence scores
        # Deterministic based on text hash
```

#### Phase 2: Hash-Based Engine (Pre-LLM)
```python
class Semantic_Text__Engine__Topics_Hash:
    def assign_topics(text, max_topics):
        # Use text hash to deterministically map to topics
        # Hash modulo 30 = primary topic
        # Secondary topics based on text length, word count, etc.
        # Still fast, no LLM
```

#### Phase 3: LLM Engine (Final)
```python
class Semantic_Text__Engine__Topics_LLM:
    def assign_topics(text, max_topics):
        # Use LLM to classify text
        # Prompt: "Classify this text into up to 3 topics from: [list of 30 topics]"
        # Parse response into topic + confidence pairs
```

### Implementation Estimate
- **New Files**: 7 files (3 schemas, 1 service, 1 enum, 1 route file, 1 engine)
- **Test Files**: 7 test files
- **Lines of Code**: ~500 production, ~700 test
- **Development Time**: 3-4 days
- **Testing Time**: 1 day
- **Total**: 4-5 days

### Dependencies
- ✅ Level 1 operational
- ✅ Level 2 optional (can work independently)

---

## Level 4: Ontology/Taxonomy Mapping

### Overview
Allows **user-provided ontology/taxonomy structures** to be applied to hash classifications, enabling custom categorization schemes.

### New Capabilities
1. Accept custom ontology/taxonomy from user
2. Map text hashes into user's taxonomy structure
3. Validate ontology structure
4. Support hierarchical relationships
5. Return mappings in user's taxonomy format

### Technical Specifications

#### New Schemas
```python
# Schema__Ontology_Node.py
class Schema__Ontology_Node(Type_Safe):
    node_id      : Safe_Str__Text                                    # Unique identifier
    label        : Safe_Str__Text                                    # Display name
    description  : Optional[Safe_Str__Text]            = None        # Node description
    parent_id    : Optional[Safe_Str__Text]            = None        # Parent node (for hierarchy)
    metadata     : Optional[Dict[str, str]]            = None        # Additional attributes
    children     : Optional[List['Schema__Ontology_Node']] = None   # Child nodes

# Schema__User_Ontology.py
class Schema__User_Ontology(Type_Safe):
    ontology_id  : Safe_Str__Text                                    # Unique ontology identifier
    name         : Safe_Str__Text                                    # Ontology name
    version      : Safe_Str__Version                                 # Ontology version
    root_nodes   : List[Schema__Ontology_Node]                       # Top-level nodes
    total_nodes  : Safe_UInt                                         # Total node count

# Schema__Classification__Ontology_Request.py
class Schema__Classification__Ontology_Request(Type_Safe):
    hash_mapping     : Dict[Safe_Str__Hash, str]
    user_ontology    : Schema__User_Ontology                         # User's custom taxonomy
    mapping_mode     : Enum__Ontology_Mapping_Mode = BEST_FIT        # How to map
    min_confidence   : Safe_Float = Safe_Float(0.3)                  # Minimum confidence
    include_path     : bool = True                                   # Include full path in hierarchy

# Schema__Classification__Ontology_Response.py
class Schema__Classification__Ontology_Response(Type_Safe):
    hash_ontology_mappings : Dict[Safe_Str__Hash, List[Schema__Ontology_Mapping]]  # Hash → mappings
    ontology_distribution  : Dict[str, Safe_UInt]                    # Node_id → count
    unmapped_hashes        : List[Safe_Str__Hash]                    # Hashes that couldn't map
    total_hashes           : Safe_UInt
    mapped_count           : Safe_UInt
    success                : bool

# Schema__Ontology_Mapping.py
class Schema__Ontology_Mapping(Type_Safe):
    node_id      : Safe_Str__Text                                    # Matched node
    node_path    : List[Safe_Str__Text]                              # Full path from root
    confidence   : Safe_Float__Text__Classification                  # Mapping confidence
    reasoning    : Optional[Safe_Str__Text] = None                   # Why this mapping (for LLM mode)
```

#### New Enums
```python
# Enum__Ontology_Mapping_Mode.py
class Enum__Ontology_Mapping_Mode(str, Enum):
    BEST_FIT       = 'best-fit'        # Map to single best node
    MULTI_LABEL    = 'multi-label'     # Map to multiple nodes
    HIERARCHICAL   = 'hierarchical'    # Map to node + all ancestors
    LEAF_ONLY      = 'leaf-only'       # Only map to leaf nodes
```

#### New Services
```python
# Classification__Ontology__Service.py
class Classification__Ontology__Service(Type_Safe):
    semantic_text_service : Semantic_Text__Service
    
    def validate_ontology(ontology) -> ValidationResult:
        # Validate ontology structure
        # Check for cycles, orphans, duplicates
        # Ensure all required fields present
    
    def map_to_ontology(request) -> Response:
        # Validate user ontology
        # Classify each hash
        # Map classifications to ontology nodes
        # Build paths in hierarchy
        # Return mappings with confidence
    
    def _find_best_match(text, ontology_nodes) -> List[Match]:
        # Match text to ontology nodes
        # Phase 1: Random/hash-based matching
        # Phase 2: LLM-based semantic matching
    
    def _build_node_path(node_id, ontology) -> List[str]:
        # Traverse from node to root
        # Build complete path
```

#### New Routes
```python
# Routes__Semantic_Classification__Ontology.py
POST /semantic-classification/ontology/validate
  → Validate user ontology structure

POST /semantic-classification/ontology/map
  → Map hashes to user ontology

POST /semantic-classification/ontology/preview
  → Preview how mapping would work (sample)
```

### API Examples

#### User Ontology Structure
```json
{
  "ontology_id": "company-project-taxonomy-v1",
  "name": "Project Classification Taxonomy",
  "version": "1.0.0",
  "root_nodes": [
    {
      "node_id": "eng",
      "label": "Engineering",
      "children": [
        {
          "node_id": "eng-backend",
          "label": "Backend Development",
          "parent_id": "eng"
        },
        {
          "node_id": "eng-frontend",
          "label": "Frontend Development",
          "parent_id": "eng"
        }
      ]
    },
    {
      "node_id": "ops",
      "label": "Operations",
      "children": [
        {
          "node_id": "ops-devops",
          "label": "DevOps",
          "parent_id": "ops"
        }
      ]
    }
  ]
}
```

#### Map to Ontology
```json
POST /semantic-classification/ontology/map
{
  "hash_mapping": {
    "abc1234567": "Implemented new API endpoint for user authentication"
  },
  "user_ontology": {...},
  "mapping_mode": "hierarchical",
  "min_confidence": 0.3,
  "include_path": true
}

Response:
{
  "hash_ontology_mappings": {
    "abc1234567": [
      {
        "node_id": "eng-backend",
        "node_path": ["eng", "eng-backend"],
        "confidence": 0.82,
        "reasoning": "Contains API and authentication keywords typical of backend work"
      }
    ]
  },
  "ontology_distribution": {
    "eng-backend": 1
  },
  "mapped_count": 1
}
```

### Ontology Mapping Engine Strategy

#### Phase 1: Keyword-Based Matching
```python
class Ontology_Mapping__Engine__Keywords:
    def map_text_to_ontology(text, ontology):
        # Extract keywords from node labels/descriptions
        # Match text keywords to ontology keywords
        # Score based on keyword overlap
        # Return best matches with confidence
```

#### Phase 2: LLM-Based Matching
```python
class Ontology_Mapping__Engine__LLM:
    def map_text_to_ontology(text, ontology):
        # Provide full ontology structure to LLM
        # Ask LLM to classify text into ontology
        # Request reasoning for classification
        # Parse response with confidence scores
```

### Implementation Estimate
- **New Files**: 10 files (6 schemas, 1 service, 1 enum, 1 route file, 1 engine)
- **Test Files**: 8 test files
- **Lines of Code**: ~700 production, ~900 test
- **Development Time**: 4-5 days
- **Testing Time**: 1-2 days
- **Total**: 5-7 days

### Dependencies
- ✅ Level 1 operational
- ✅ Levels 2-3 optional

---

## Level 5: Sub-Criteria Explainability

### Overview
Breaks down each classification criterion into **5-6 sub-criteria** with individual ratings, enabling explainability and transparency in classification decisions.

### New Capabilities
1. Rate sub-criteria for each main criterion
2. Show formula for aggregate criterion score
3. Provide explainability for classifications
4. Enable fine-tuned filtering on sub-criteria
5. Support custom sub-criteria weights

### Technical Specifications

#### Sub-Criteria Definitions

##### Positivity Sub-Criteria
1. **Joy** (0.0-1.0) - Expression of happiness, delight
2. **Hope** (0.0-1.0) - Future-oriented optimism
3. **Satisfaction** (0.0-1.0) - Contentment, fulfillment
4. **Enthusiasm** (0.0-1.0) - Excitement, eagerness
5. **Gratitude** (0.0-1.0) - Thankfulness, appreciation
6. **Pride** (0.0-1.0) - Achievement, accomplishment

Formula: `positivity = weighted_average(joy, hope, satisfaction, enthusiasm, gratitude, pride)`

##### Negativity Sub-Criteria
1. **Anger** (0.0-1.0) - Frustration, rage
2. **Sadness** (0.0-1.0) - Sorrow, disappointment
3. **Fear** (0.0-1.0) - Anxiety, worry
4. **Disgust** (0.0-1.0) - Revulsion, distaste
5. **Frustration** (0.0-1.0) - Irritation, annoyance
6. **Regret** (0.0-1.0) - Remorse, guilt

##### Urgency Sub-Criteria
1. **Time_Pressure** (0.0-1.0) - Deadline constraints
2. **Importance** (0.0-1.0) - Priority level
3. **Consequences** (0.0-1.0) - Impact of inaction
4. **Call_To_Action** (0.0-1.0) - Explicit requests for action
5. **Scarcity** (0.0-1.0) - Limited availability
6. **Immediacy** (0.0-1.0) - "Now" vs "Later"

##### Bias Sub-Criteria
1. **Confirmation** (0.0-1.0) - Reinforces existing beliefs
2. **Selection** (0.0-1.0) - Cherry-picks information
3. **Attribution** (0.0-1.0) - Misattributes causes
4. **Anchoring** (0.0-1.0) - Over-relies on initial info
5. **Framing** (0.0-1.0) - Presents info in loaded way
6. **Groupthink** (0.0-1.0) - Pressure to conform

##### Toxicity Sub-Criteria
1. **Insult** (0.0-1.0) - Personal attacks
2. **Profanity** (0.0-1.0) - Vulgar language
3. **Threat** (0.0-1.0) - Intimidation, violence
4. **Discrimination** (0.0-1.0) - Bias against groups
5. **Sexual_Content** (0.0-1.0) - Inappropriate sexual content
6. **Hate_Speech** (0.0-1.0) - Targeting protected groups

#### New Schemas
```python
# Schema__Sub_Criteria_Rating.py
class Schema__Sub_Criteria_Rating(Type_Safe):
    sub_criterion_name : Safe_Str__Text
    rating             : Safe_Float__Text__Classification
    weight             : Safe_Float = Safe_Float(1.0)  # Contribution weight
    contribution       : Safe_Float                     # (rating * weight)

# Schema__Criteria_Breakdown.py
class Schema__Criteria_Breakdown(Type_Safe):
    main_criterion     : Enum__Text__Classification__Criteria
    aggregate_score    : Safe_Float__Text__Classification
    sub_criteria       : List[Schema__Sub_Criteria_Rating]
    formula            : Safe_Str__Text                 # How aggregate was calculated
    confidence         : Safe_Float = Safe_Float(1.0)  # Confidence in classification

# Schema__Classification__Explainable_Request.py
class Schema__Classification__Explainable_Request(Type_Safe):
    hash_mapping           : Dict[Safe_Str__Hash, str]
    classification_criteria : List[Enum__Text__Classification__Criteria]
    include_sub_criteria   : bool = True
    include_formula        : bool = True
    custom_weights         : Optional[Dict[str, Dict[str, float]]] = None  # criterion → {sub_criterion → weight}

# Schema__Classification__Explainable_Response.py
class Schema__Classification__Explainable_Response(Type_Safe):
    hash_breakdowns        : Dict[Safe_Str__Hash, List[Schema__Criteria_Breakdown]]
    total_hashes           : Safe_UInt
    success                : bool
```

#### New Enums
```python
# Enum__Sub_Criterion__Positivity.py
class Enum__Sub_Criterion__Positivity(str, Enum):
    JOY          = 'joy'
    HOPE         = 'hope'
    SATISFACTION = 'satisfaction'
    ENTHUSIASM   = 'enthusiasm'
    GRATITUDE    = 'gratitude'
    PRIDE        = 'pride'

# (Similar enums for Negativity, Urgency, Bias, Toxicity)
```

#### New Services
```python
# Classification__Sub_Criteria__Service.py
class Classification__Sub_Criteria__Service(Type_Safe):
    semantic_text_service : Semantic_Text__Service
    
    def classify_with_breakdown(request) -> Response:
        # Classify each hash
        # For each criterion, rate all sub-criteria
        # Calculate aggregate using formula
        # Build explainable breakdown
    
    def filter_by_sub_criteria(request) -> Response:
        # Enable filtering on sub-criteria level
        # Example: joy > 0.8 AND enthusiasm > 0.7
    
    def _calculate_aggregate(sub_ratings, weights) -> float:
        # Apply formula to combine sub-criteria
        # Default: weighted average
        # Custom: user-provided formula
    
    def _generate_formula_text(criterion, weights) -> str:
        # Generate human-readable formula
        # Example: "positivity = (joy*0.2 + hope*0.15 + satisfaction*0.25 + ...)"
```

#### New Routes
```python
# Extend Routes__Semantic_Classification.py
POST /semantic-classification/explainable/rate
  → Rate with full sub-criteria breakdown

POST /semantic-classification/explainable/breakdown
  → Get detailed breakdown for specific hash

POST /semantic-classification/explainable/filter
  → Filter on sub-criteria level
```

### API Examples

#### Explainable Rating
```json
POST /semantic-classification/explainable/rate
{
  "hash_mapping": {
    "abc1234567": "I'm so thrilled about this amazing opportunity!"
  },
  "classification_criteria": ["positivity"],
  "include_sub_criteria": true,
  "include_formula": true
}

Response:
{
  "hash_breakdowns": {
    "abc1234567": [
      {
        "main_criterion": "positivity",
        "aggregate_score": 0.87,
        "sub_criteria": [
          {"sub_criterion_name": "joy", "rating": 0.92, "weight": 0.20, "contribution": 0.184},
          {"sub_criterion_name": "hope", "rating": 0.75, "weight": 0.15, "contribution": 0.1125},
          {"sub_criterion_name": "satisfaction", "rating": 0.68, "weight": 0.20, "contribution": 0.136},
          {"sub_criterion_name": "enthusiasm", "rating": 0.98, "weight": 0.25, "contribution": 0.245},
          {"sub_criterion_name": "gratitude", "rating": 0.55, "weight": 0.10, "contribution": 0.055},
          {"sub_criterion_name": "pride", "rating": 0.72, "weight": 0.10, "contribution": 0.072}
        ],
        "formula": "positivity = (joy*0.2 + hope*0.15 + satisfaction*0.2 + enthusiasm*0.25 + gratitude*0.1 + pride*0.1)",
        "confidence": 0.95
      }
    ]
  }
}
```

### Sub-Criteria Engine Strategy

#### Phase 1: Derived from Main Criterion (Random)
```python
class Sub_Criteria__Engine__Derived:
    def rate_sub_criteria(text, main_rating):
        # Use main criterion rating as baseline
        # Add random variance to create sub-ratings
        # Ensure they average to main rating
        # Still fast, no LLM needed
```

#### Phase 2: LLM with Structured Output
```python
class Sub_Criteria__Engine__LLM:
    def rate_sub_criteria(text, criterion):
        # Prompt: "Rate this text on: joy, hope, satisfaction, enthusiasm, gratitude, pride"
        # Request JSON output with scores
        # Validate response structure
        # Calculate aggregate from sub-criteria
```

### Implementation Estimate
- **New Files**: 12 files (4 schemas, 1 service, 5 enums, 2 route extensions)
- **Test Files**: 10 test files
- **Lines of Code**: ~800 production, ~1000 test
- **Development Time**: 5-6 days
- **Testing Time**: 2 days
- **Total**: 7-8 days

### Dependencies
- ✅ Level 1 operational
- ✅ Level 2 recommended (uses multi-criteria)

---

## Level 6: Semantic Graph Generation

### Overview
Generates **semantic graphs** from hash mappings, creating a two-step intelligent taxonomy followed by mapping hashes into the generated structure.

### New Capabilities
1. **Step 1**: Generate intelligent taxonomy from hash batch
   - Analyze all texts to discover themes
   - Build hierarchical taxonomy automatically
   - Create semantic relationships between nodes

2. **Step 2**: Map hashes into generated taxonomy
   - Place each hash in appropriate taxonomy nodes
   - Support multiple placements per hash
   - Generate edge relationships between hashes

3. **Graph Operations**:
   - Query graph structure
   - Find similar hashes
   - Traverse relationships
   - Export to graph database

### Technical Specifications

#### New Schemas
```python
# Schema__Semantic_Node.py
class Schema__Semantic_Node(Type_Safe):
    node_id          : Safe_Str__Text
    node_type        : Enum__Semantic_Node_Type
    label            : Safe_Str__Text
    description      : Optional[Safe_Str__Text] = None
    level            : Safe_UInt                # Hierarchy level (0=root)
    parent_id        : Optional[Safe_Str__Text] = None
    children_ids     : List[Safe_Str__Text] = []
    hash_members     : List[Safe_Str__Hash] = []  # Hashes in this node
    metadata         : Dict[str, Any] = {}

# Schema__Semantic_Edge.py
class Schema__Semantic_Edge(Type_Safe):
    edge_id          : Safe_Str__Text
    source_id        : Safe_Str__Text          # Source node/hash
    target_id        : Safe_Str__Text          # Target node/hash
    edge_type        : Enum__Semantic_Edge_Type
    weight           : Safe_Float = Safe_Float(1.0)
    metadata         : Dict[str, Any] = {}

# Schema__Semantic_Graph.py
class Schema__Semantic_Graph(Type_Safe):
    graph_id         : Safe_Str__Text
    name             : Safe_Str__Text
    nodes            : Dict[Safe_Str__Text, Schema__Semantic_Node]
    edges            : List[Schema__Semantic_Edge]
    root_nodes       : List[Safe_Str__Text]
    metadata         : Dict[str, Any] = {}
    created_at       : str
    version          : Safe_Str__Version

# Schema__Graph_Build_Request.py
class Schema__Graph_Build_Request(Type_Safe):
    hash_mapping              : Dict[Safe_Str__Hash, str]
    taxonomy_generation_mode  : Enum__Taxonomy_Generation_Mode = AUTO
    max_taxonomy_levels       : Safe_UInt = Safe_UInt(3)
    max_nodes_per_level       : Safe_UInt = Safe_UInt(10)
    min_cluster_size          : Safe_UInt = Safe_UInt(2)
    enable_hash_relationships : bool = True
    relationship_threshold    : Safe_Float = Safe_Float(0.7)

# Schema__Graph_Build_Response.py
class Schema__Graph_Build_Response(Type_Safe):
    semantic_graph     : Schema__Semantic_Graph
    taxonomy_summary   : Schema__Taxonomy_Summary
    hash_placements    : Dict[Safe_Str__Hash, List[Safe_Str__Text]]  # Hash → node_ids
    success            : bool
    generation_time_ms : Safe_UInt

# Schema__Graph_Query_Request.py
class Schema__Graph_Query_Request(Type_Safe):
    graph_id         : Safe_Str__Text
    query_type       : Enum__Graph_Query_Type
    query_params     : Dict[str, Any]

# Schema__Graph_Query_Response.py
class Schema__Graph_Query_Response(Type_Safe):
    results          : List[Any]                  # Query-dependent results
    result_count     : Safe_UInt
    success          : bool
```

#### New Enums
```python
# Enum__Semantic_Node_Type.py
class Enum__Semantic_Node_Type(str, Enum):
    ROOT       = 'root'          # Top-level node
    CATEGORY   = 'category'      # Mid-level category
    CLUSTER    = 'cluster'       # Leaf cluster
    HASH       = 'hash'          # Individual hash node

# Enum__Semantic_Edge_Type.py
class Enum__Semantic_Edge_Type(str, Enum):
    PARENT_CHILD  = 'parent-child'    # Hierarchical relationship
    SIMILAR       = 'similar'         # Semantic similarity
    RELATED       = 'related'         # General relationship
    SEQUENCE      = 'sequence'        # Temporal/sequential
    REFERENCE     = 'reference'       # References/citations

# Enum__Taxonomy_Generation_Mode.py
class Enum__Taxonomy_Generation_Mode(str, Enum):
    AUTO           = 'auto'           # Fully automatic
    GUIDED         = 'guided'         # User provides hints
    TEMPLATE       = 'template'       # Use predefined template

# Enum__Graph_Query_Type.py
class Enum__Graph_Query_Type(str, Enum):
    FIND_NODE      = 'find-node'          # Find specific node
    FIND_SIMILAR   = 'find-similar'       # Find similar hashes
    GET_PATH       = 'get-path'           # Get path between nodes
    GET_NEIGHBORS  = 'get-neighbors'      # Get adjacent nodes
    TRAVERSE       = 'traverse'           # Traverse from node
```

#### New Services
```python
# Semantic_Graph__Builder.py
class Semantic_Graph__Builder(Type_Safe):
    semantic_text_service : Semantic_Text__Service
    
    def build_graph(request) -> Response:
        # Two-step process:
        # 1. Generate taxonomy
        # 2. Map hashes into taxonomy
    
    def generate_taxonomy(hash_mapping, params) -> Schema__Semantic_Graph:
        # Step 1: Analyze all texts
        # Discover themes and patterns
        # Build hierarchical structure
        # Create taxonomy nodes
    
    def map_hashes_to_taxonomy(hash_mapping, taxonomy) -> Dict:
        # Step 2: Place each hash
        # Determine best fit node(s)
        # Create hash relationships
        # Build complete graph
    
    def _cluster_texts(texts, max_clusters) -> List[Cluster]:
        # Group similar texts
        # Phase 1: Simple clustering (length, keywords)
        # Phase 2: LLM-based semantic clustering
    
    def _generate_labels(cluster) -> str:
        # Generate descriptive label for cluster
        # Phase 1: Most common words
        # Phase 2: LLM-generated label
    
    def _find_relationships(hash1, hash2, threshold) -> Optional[Edge]:
        # Determine if hashes are related
        # Calculate similarity score
        # Create edge if above threshold

# Semantic_Graph__Query.py
class Semantic_Graph__Query(Type_Safe):
    
    def query_graph(request) -> Response:
        # Execute graph query
        # Return matching nodes/edges
    
    def find_similar_hashes(graph, hash_id, top_n) -> List:
        # Find N most similar hashes
        # Use graph structure + edge weights
    
    def get_path(graph, source_id, target_id) -> List:
        # Find path between nodes
        # Return list of nodes in path
    
    def traverse_from_node(graph, node_id, depth) -> Graph:
        # Get subgraph from node
        # Traverse N levels deep

# Semantic_Graph__Exporter.py
class Semantic_Graph__Exporter(Type_Safe):
    
    def export_to_json(graph) -> str:
        # Export graph as JSON
    
    def export_to_graphdb(graph, db_config) -> bool:
        # Export to your serverless graph DB
        # Create nodes and edges
        # Preserve relationships
```

#### New Routes
```python
# Routes__Semantic_Graph.py
POST /semantic/graph/build
  → Build semantic graph from hash mapping

POST /semantic/graph/query
  → Query existing graph

GET /semantic/graph/{graph_id}
  → Get graph by ID

POST /semantic/graph/export
  → Export graph to various formats

POST /semantic/graph/visualize
  → Get visualization-ready data
```

### API Examples

#### Build Graph
```json
POST /semantic/graph/build
{
  "hash_mapping": {
    "abc1234567": "Machine learning improves accuracy",
    "def1234567": "Neural networks deep learning",
    "ghi1234567": "Customer satisfaction metrics",
    "jkl1234567": "User retention analysis",
    "mno1234567": "AI powered recommendations"
  },
  "taxonomy_generation_mode": "auto",
  "max_taxonomy_levels": 3,
  "max_nodes_per_level": 5,
  "enable_hash_relationships": true
}

Response:
{
  "semantic_graph": {
    "graph_id": "graph-20251109-001",
    "nodes": {
      "root-1": {
        "node_id": "root-1",
        "node_type": "root",
        "label": "Technical Themes",
        "level": 0,
        "children_ids": ["cat-1", "cat-2"]
      },
      "cat-1": {
        "node_id": "cat-1",
        "node_type": "category",
        "label": "AI & Machine Learning",
        "level": 1,
        "parent_id": "root-1",
        "children_ids": ["cluster-1"],
        "hash_members": ["abc1234567", "def1234567", "mno1234567"]
      },
      "cat-2": {
        "node_id": "cat-2",
        "node_type": "category",
        "label": "Customer Metrics",
        "level": 1,
        "parent_id": "root-1",
        "children_ids": ["cluster-2"],
        "hash_members": ["ghi1234567", "jkl1234567"]
      }
    },
    "edges": [
      {
        "edge_id": "edge-1",
        "source_id": "abc1234567",
        "target_id": "def1234567",
        "edge_type": "similar",
        "weight": 0.85
      },
      {
        "edge_id": "edge-2",
        "source_id": "ghi1234567",
        "target_id": "jkl1234567",
        "edge_type": "similar",
        "weight": 0.72
      }
    ]
  },
  "hash_placements": {
    "abc1234567": ["cat-1", "cluster-1"],
    "def1234567": ["cat-1", "cluster-1"]
  }
}
```

#### Query Graph
```json
POST /semantic/graph/query
{
  "graph_id": "graph-20251109-001",
  "query_type": "find-similar",
  "query_params": {
    "hash_id": "abc1234567",
    "top_n": 3,
    "min_similarity": 0.5
  }
}

Response:
{
  "results": [
    {"hash_id": "def1234567", "similarity": 0.85, "path": ["cat-1"]},
    {"hash_id": "mno1234567", "similarity": 0.73, "path": ["cat-1"]}
  ],
  "result_count": 2
}
```

### Graph Generation Engine Strategy

#### Phase 1: Simple Clustering
```python
class Semantic_Graph__Engine__Simple:
    def generate_taxonomy(texts):
        # Group by text length
        # Group by keyword frequency
        # Create hierarchy based on groups
        # Fast, deterministic, no LLM
    
    def find_relationships(hash1, hash2):
        # Calculate Jaccard similarity
        # Use edit distance
        # Simple metrics, fast
```

#### Phase 2: LLM-Based Generation
```python
class Semantic_Graph__Engine__LLM:
    def generate_taxonomy(texts):
        # Send batch of texts to LLM
        # Prompt: "Analyze these texts and create a 3-level taxonomy"
        # Parse LLM response into taxonomy structure
        # Create rich, semantic categories
    
    def generate_labels(cluster_texts):
        # Prompt: "Generate a concise label for these texts: [...]"
        # Get LLM-generated descriptive label
    
    def find_relationships(text1, text2):
        # Prompt: "Are these texts related? Score 0-1"
        # Get semantic similarity from LLM
```

### Implementation Estimate
- **New Files**: 15 files (8 schemas, 3 services, 4 enums, 1 route file)
- **Test Files**: 12 test files
- **Lines of Code**: ~1200 production, ~1400 test
- **Development Time**: 7-10 days
- **Testing Time**: 2-3 days
- **Total**: 9-13 days

### Dependencies
- ✅ Level 1 operational
- ✅ Levels 2-5 optional but recommended

---

## Engine Development Strategy

### Phase 1: Non-LLM Engines (All Levels)

#### Priority Order
1. **Random Engine** (Already exists for Level 1)
   - Continue using for initial development
   - Fast, deterministic for testing

2. **Hash-Based Engine** (New - for all levels)
   ```python
   class Semantic_Text__Engine__Hash_Based:
       def classify_text(text, criteria):
           # Use text hash to generate deterministic ratings
           # hash(text + criterion) % 100 / 100 = rating
           # Different texts = different ratings
           # Same text = same rating (consistent)
   ```

3. **Pre-Configured Engine** (New - for specific use cases)
   ```python
   class Semantic_Text__Engine__Pre_Configured:
       config_mappings : Dict[str, Dict[str, float]]
       
       def classify_text(text, criteria):
           # Look up pre-defined ratings
           # Useful for demos, testing, benchmarks
           # Can load from JSON/YAML config
   ```

### Phase 2: LLM Engines (After all levels work)

#### Single LLM Engine
```python
class Semantic_Text__Engine__LLM_Single:
    llm_provider : str  # 'anthropic', 'openai', 'together', etc.
    model_name   : str  # 'claude-sonnet-4', 'gpt-4', etc.
    
    def classify_text(text, criteria):
        # Single LLM call per text
        # Rate all criteria in one prompt
        # Parse structured response
        # Cache results aggressively
```

#### Multiple LLM Engine (Ensemble)
```python
class Semantic_Text__Engine__LLM_Multiple:
    engines : List[Semantic_Text__Engine__LLM_Single]
    
    def classify_text(text, criteria):
        # Call multiple LLMs
        # Aggregate responses
        # Detect disagreement
        # Return consensus + variance
```

---

## Cross-Cutting Concerns

### 1. Caching Strategy

#### Cache Architecture
```
Level 1: cache_key = hash(text + criterion)
Level 2: cache_key = hash(text + criteria_list + aggregate_mode)
Level 3: cache_key = hash(text + "topics" + max_topics)
Level 4: cache_key = hash(text + ontology_id + mapping_mode)
Level 5: cache_key = hash(text + criterion + "sub_criteria")
Level 6: cache_key = hash(all_texts + taxonomy_params)
```

#### Cache Service Integration
```python
class Classification__Cache__Manager(Type_Safe):
    cache_service : Cache__Service
    
    def get_classification(cache_key) -> Optional[Classification]:
        # Check cache first
        # Return cached result if exists
        # Return None if not cached
    
    def store_classification(cache_key, result, ttl=86400):
        # Store in cache with TTL
        # Default: 24 hours
        # Longer for hash-based (deterministic)
        # Shorter for LLM-based (may evolve)
    
    def invalidate_pattern(pattern):
        # Invalidate cache by pattern
        # Example: invalidate all Level 3 results
```

### 2. Performance Monitoring

#### Metrics to Track
```python
class Classification__Metrics(Type_Safe):
    level                  : int
    engine_type            : str
    total_requests         : Safe_UInt
    cache_hits             : Safe_UInt
    cache_misses           : Safe_UInt
    avg_response_time_ms   : Safe_UInt
    p95_response_time_ms   : Safe_UInt
    p99_response_time_ms   : Safe_UInt
    error_rate             : Safe_Float
```

### 3. Testing Strategy

#### Test Pyramid for Each Level
```
Unit Tests (60%):
  - All schemas
  - All services
  - All engines
  - Edge cases
  
Integration Tests (30%):
  - Routes + Services
  - Service + Engine
  - End-to-end flows
  
Performance Tests (10%):
  - Load testing
  - Stress testing
  - Cache effectiveness
```

#### Test Data Strategy
```python
# test_fixtures.py
STANDARD_TEST_HASHES = {
    "highly_positive": {
        "abc1234567": "Amazing wonderful fantastic experience!",
        "expected_positivity": 0.95
    },
    "highly_negative": {
        "def1234567": "Terrible awful horrible disaster",
        "expected_negativity": 0.95
    },
    "neutral": {
        "ghi1234567": "The document contains information",
        "expected_positivity": 0.5,
        "expected_negativity": 0.5
    }
}
```

### 4. Error Handling

#### Standard Error Response
```python
class Schema__Classification__Error_Response(Type_Safe):
    error_code       : Safe_Str__Text
    error_message    : Safe_Str__Text
    error_details    : Optional[Dict] = None
    level            : int
    timestamp        : str
    request_id       : Safe_Str__Text
```

#### Error Codes by Level
```
Level 1: CL1-xxx (Classification Level 1)
Level 2: CL2-xxx
Level 3: CL3-xxx
Level 4: CL4-xxx (e.g., CL4-001 = Invalid Ontology Structure)
Level 5: CL5-xxx
Level 6: CL6-xxx
```

---

## Development Timeline

### Recommended Sequence

```
Week 1-2: Foundation
├─ Level 1 ✅ (Already complete)
└─ Level 2: Multi-Criteria (3-4 days)

Week 3: Topics & Ontology
├─ Level 3: Topics (4-5 days)
└─ Buffer for integration testing

Week 4: Advanced Features
├─ Level 4: Ontology (5-7 days)
└─ Buffer for testing

Week 5-6: Explainability & Graphs
├─ Level 5: Sub-Criteria (7-8 days)
└─ Level 6: Semantic Graphs (9-13 days)

Week 7: Testing & Polish
├─ End-to-end testing
├─ Performance optimization
├─ Documentation
└─ Deployment preparation

Week 8+: LLM Integration (Optional)
├─ Swap engines to LLM-based
├─ Prompt engineering
├─ Performance tuning
└─ Final deployment
```

### Parallel Development Opportunities

**Team A: Levels 2-3** (Can work in parallel)
- Level 2 depends only on Level 1
- Level 3 independent of Level 2

**Team B: Caching Layer**
- Build cache integration
- Works across all levels
- Can develop alongside features

**Team C: Testing Infrastructure**
- Build test fixtures
- Create performance tests
- Develop load testing framework

---

## Risk Assessment & Mitigation

### Technical Risks

#### Risk 1: Graph Generation Complexity (Level 6)
**Severity**: High  
**Likelihood**: Medium  
**Mitigation**:
- Start with simple clustering algorithm
- Use Level 3 topics as fallback taxonomy
- Phase LLM integration last
- Build visualization tools early for debugging

#### Risk 2: LLM Integration Challenges
**Severity**: Medium  
**Likelihood**: Medium  
**Mitigation**:
- Architecture is engine-agnostic
- Test with multiple LLM providers
- Keep random/hash engines as fallback
- Implement aggressive caching

#### Risk 3: Performance at Scale
**Severity**: Medium  
**Likelihood**: Low  
**Mitigation**:
- Design for caching from day 1
- Benchmark at each level
- Use async/parallel processing
- Monitor performance metrics

#### Risk 4: Ontology Validation (Level 4)
**Severity**: Low  
**Likelihood**: Medium  
**Mitigation**:
- Comprehensive validation logic
- Clear error messages
- Provide example ontologies
- Support ontology templates

### Timeline Risks

#### Risk 1: Underestimated Complexity
**Mitigation**:
- 20% buffer built into estimates
- Each level independently deployable
- Can skip levels if needed
- MVP vs Full Feature separation

#### Risk 2: Dependency on Level 1
**Mitigation**:
- Level 1 fully tested before starting Level 2
- Clear integration contract
- Backward compatibility guaranteed

---

## Success Criteria

### Per-Level Criteria

**Level 2**:
- [  ] Multi-criteria classification works correctly
- [  ] AND/OR filtering logic accurate
- [  ] Aggregate scoring modes functional
- [  ] 100% test coverage
- [  ] Response time < 50ms (non-LLM)

**Level 3**:
- [  ] 30 topics defined and tested
- [  ] Topic assignment accurate (validated against test set)
- [  ] Topic distribution analysis works
- [  ] Filter by topics functional
- [  ] Response time < 50ms (non-LLM)

**Level 4**:
- [  ] Custom ontology validation robust
- [  ] Mapping to user ontology accurate
- [  ] Handles hierarchical structures correctly
- [  ] Path generation works
- [  ] Response time < 100ms (non-LLM)

**Level 5**:
- [  ] All sub-criteria defined for 5 main criteria
- [  ] Sub-criteria ratings accurate
- [  ] Formula calculation correct
- [  ] Explainability clear and useful
- [  ] Response time < 100ms (non-LLM)

**Level 6**:
- [  ] Taxonomy generation produces sensible results
- [  ] Hash mapping accurate
- [  ] Graph structure valid
- [  ] Query operations functional
- [  ] Export to graph DB works
- [  ] Response time < 500ms (non-LLM)

### Overall Success Criteria

- [  ] All 6 levels operational with non-LLM engines
- [  ] 100% test coverage across all levels
- [  ] Documentation complete for all levels
- [  ] Performance benchmarks documented
- [  ] Cache integration working
- [  ] Monitoring and metrics in place
- [  ] Ready for LLM engine swap

---

## Documentation Requirements

### Per-Level Documentation

1. **API Documentation**
   - OpenAPI/Swagger specs
   - Request/response examples
   - Error codes and handling

2. **Architecture Documentation**
   - System diagrams
   - Data flow diagrams
   - Integration points

3. **Developer Documentation**
   - Setup instructions
   - Testing guide
   - Deployment guide

4. **User Documentation**
   - Feature descriptions
   - Use cases
   - Best practices

### Code Documentation

- Inline comments on all methods (following your guidelines)
- Type hints on all functions
- Docstrings for complex logic
- README for each major component

---

## Post-Deployment: LLM Integration

### LLM Provider Selection Criteria

1. **Performance**: Latency, throughput
2. **Cost**: Per-token pricing
3. **Quality**: Classification accuracy
4. **Reliability**: Uptime, consistency
5. **Features**: Structured output, function calling

### Recommended Providers by Level

**Levels 1-3** (Simple Classification):
- Claude Sonnet 4 (Best quality/speed balance)
- GPT-4o (Alternative)
- Gemini Flash (Cost-effective)

**Levels 4-5** (Complex Reasoning):
- Claude Opus 4 (Best reasoning)
- GPT-4 (Alternative)
- Claude Sonnet 4 (Balance)

**Level 6** (Graph Generation):
- Claude Opus 4 (Best for complex tasks)
- GPT-4 with fine-tuning (Alternative)

### Prompt Engineering Strategy

```python
# Level 1: Simple Classification
PROMPT_TEMPLATE_L1 = """
Rate the following text on a scale of 0.0 to 1.0 for {criterion}.
Text: "{text}"

Respond with only a number between 0.0 and 1.0.
"""

# Level 5: Explainable Sub-Criteria
PROMPT_TEMPLATE_L5 = """
Rate the following text on these 6 sub-criteria of {criterion}:
{sub_criteria_list}

Text: "{text}"

Respond with JSON:
{
  "sub_criteria": [
    {"name": "joy", "rating": 0.8, "reasoning": "..."},
    ...
  ]
}
"""

# Level 6: Graph Generation
PROMPT_TEMPLATE_L6 = """
Analyze these {count} texts and create a 3-level taxonomy:

Texts:
{text_list}

Requirements:
- Level 1: 3-5 major themes
- Level 2: 2-3 subcategories per theme
- Level 3: Specific clusters

Respond with JSON taxonomy structure.
"""
```

---

## Conclusion

This technical brief outlines a comprehensive 6-level architecture for semantic text classification. Key points:

1. **Progressive Complexity**: Each level adds one major capability
2. **Engine Agnostic**: Start with simple engines, upgrade to LLM
3. **Independent Deployment**: Each level can ship separately
4. **Performance First**: Validate architecture before LLM complexity
5. **Cache Ready**: Designed for aggressive caching from day 1
6. **Type Safe**: Full validation at all boundaries
7. **Test Driven**: 100% coverage at each level

**Total Estimate**: 7-8 weeks for full implementation (Levels 1-6 + LLM integration)

**Recommended Path**:
1. Complete Levels 2-6 with non-LLM engines (5-6 weeks)
2. Validate architecture, performance, UX (1 week)
3. Integrate LLM engines (1-2 weeks)
4. Final testing and deployment (1 week)

The architecture is sound, the plan is detailed, and the foundation (Level 1) is solid. Ready to proceed! 🚀