# Technical Brief: Semantic Text Service - AWS Comprehend Integration

**Version:** v0.5.24  
**Date:** 2025-01-15

---

## 1. Executive Summary

This document outlines the transformation of the **MGraph AI Semantic Text Service** from using pseudo-random hash-based classification to real ML-powered sentiment analysis via **AWS Comprehend Service** integration.

**Key Changes:**
- Replace experimental classification criteria (bias, urgency) with AWS Comprehend's 4 sentiment scores (positive, negative, neutral, mixed)
- Introduce engine selection via API path parameters (aws_comprehend, text_hash, random)
- Implement factory pattern for engine management (singleton pattern with `@cache_on_self`)
- Update all schemas to return all 4 sentiment scores instead of single criterion
- Remove `classification_criteria` from classification requests (but keep in filter requests)

**No Backward Compatibility Required:** This is a breaking change as no production clients exist yet.

---

## 2. Current State Analysis

### 2.1 Semantic Text Service (Before)

**Purpose:** Text transformation and classification using semantic graphs

**Current Classification:**
- Uses `Semantic_Text__Engine__Hash_Based` (deterministic pseudo-random)
- Experimental criteria: `POSITIVITY`, `NEGATIVITY`, `BIAS`, `URGENCY`
- Single-criterion classification: request one criterion → get one score
- Hardcoded engine in service constructor

**Architecture Issues:**
```python
# service/semantic_text/Semantic_Text__Service.py
def setup(self):
    self.semantic_text__engine = Semantic_Text__Engine__Hash_Based()  # Hardcoded!
```

**Request/Response Pattern:**
```python
# Request
{
  "hash_mapping": {"abc123": "This is great!"},
  "classification_criteria": "positivity"  # Single criterion
}

# Response  
{
  "hash_ratings": {"abc123": 0.85},  # Single score
  "classification_criteria": "positivity"
}
```

### 2.2 AWS Comprehend Service (Available)

**Purpose:** Real ML-powered text analysis via AWS Comprehend API

**Capabilities:**
- Sentiment detection (4 scores: positive, negative, neutral, mixed)
- Batch processing support (25 texts per batch, concurrent chunks)
- Multiple endpoints: direct AWS wrappers, helpers, batch operations

**Relevant Endpoint:**
```
POST /comprehend/detect-sentiment
{
  "text": "This is great!",
  "language_code": "en",
  "use_cache": false
}

Response:
{
  "sentiment": "Positive",
  "score": {
    "positive": 0.8567,
    "negative": 0.0234,
    "neutral": 0.1123,
    "mixed": 0.0076
  }
}
```

**Authentication Pattern (from QA tests):**
```python
ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__BASE_URL  = "AUTH__SERVICE__AWS__COMPREHEND__BASE_URL"
ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME  = "AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME"
ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE = "AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE"

# Usage:
server    = get_env(ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__BASE_URL)
key_name  = get_env(ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME)
key_value = get_env(ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE)
headers   = {key_name: key_value}
```

---

## 3. Design Principles & Patterns

### 3.1 Type-Safe Pattern (from osbot-utils)

**All classes inherit from `Type_Safe`:**
```python
from osbot_utils.type_safe.Type_Safe import Type_Safe

class MyClass(Type_Safe):
    field_name: FieldType  # Strict typing enforced
```

**Benefits:**
- Runtime type validation
- `.obj()` method for serialization
- Consistent error handling

### 3.2 Factory Pattern with Singleton Cache

**Pattern:** Use `@cache_on_self` decorator for expensive object creation

```python
from osbot_utils.decorators.methods.cache_on_self import cache_on_self

class MyFactory(Type_Safe):
    @cache_on_self
    def expensive_object(self):
        """Created once, cached on self"""
        return ExpensiveObject()
```

**Application:** Engine factory creates and caches engine instances

### 3.3 Service Architecture Pattern

**Service Integration via HTTP:**
- Services remain independently deployable
- Communication via REST APIs
- Authentication via headers (from environment variables)
- Pattern already used: HTML Service → Semantic Text Service

### 3.4 Path-Based Engine Selection

**Pattern:** Engine selection as path parameter (not query param or body)
```
POST /semantic-classification/{engine_mode}/rate
POST /semantic-classification/{engine_mode}/filter
```

**Rationale:**
- RESTful resource modeling (engine is a resource variant)
- Clear in OpenAPI docs
- Enables path-based routing/caching

---

## 4. New Architecture

### 4.1 System Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    API Caller (External)                    │
└─────────────────────────┬───────────────────────────────────┘
                          │
                          │ POST /{engine_mode}/rate
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│           Semantic Text Service (FastAPI)                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Routes__Semantic_Classification                      │  │
│  │  - /{engine_mode}/rate                                │  │
│  │  - /{engine_mode}/filter                              │  │
│  │  - /{engine_mode}/filter/multi                        │  │
│  └────────────────────┬──────────────────────────────────┘  │
│                       │                                      │
│                       │ get_engine(engine_mode)              │
│                       ▼                                      │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Semantic_Text__Engine__Factory                       │  │
│  │  @cache_on_self methods:                              │  │
│  │  - engine__aws_comprehend() ──┐                       │  │
│  │  - engine__hash_based()       │ Singletons            │  │
│  │  - engine__random()           │                       │  │
│  └───────────────────────────────┴───────────────────────┘  │
│                       │                                      │
│         ┌─────────────┼─────────────┐                        │
│         │             │             │                        │
│         ▼             ▼             ▼                        │
│  ┌──────────┐  ┌──────────┐  ┌─────────────────────────┐   │
│  │  Hash    │  │ Random   │  │ AWS Comprehend Engine   │   │
│  │  Based   │  │ Engine   │  │ (HTTP Client)           │   │
│  │  Engine  │  │          │  └──────────┬──────────────┘   │
│  └──────────┘  └──────────┘             │                   │
│                                          │                   │
└──────────────────────────────────────────┼───────────────────┘
                                           │
                                           │ HTTP POST
                                           │ /comprehend/detect-sentiment
                                           │
                                           ▼
                            ┌──────────────────────────────┐
                            │  AWS Comprehend Service      │
                            │  (Separate Microservice)     │
                            └──────────────────────────────┘
```

### 4.2 Engine Classification Flow

```
┌──────────────┐
│   Request    │
│ {hash→text}  │
└──────┬───────┘
       │
       ▼
┌─────────────────────────────────────────┐
│  Engine.classify_text(text)             │
│                                         │
│  ┌───────────┐  ┌────────────┐         │
│  │Hash-Based │  │   Random   │         │
│  │           │  │            │         │
│  │Determinst.│  │ Dirichlet  │         │
│  │Hash Calc  │  │ Random Gen │         │
│  └─────┬─────┘  └──────┬─────┘         │
│        │               │               │
│        └───────┬───────┘               │
│                │                       │
│  ┌─────────────▼──────────────┐        │
│  │  AWS Comprehend Engine     │        │
│  │                            │        │
│  │  HTTP POST to:             │        │
│  │  /comprehend/              │        │
│  │   detect-sentiment         │        │
│  │                            │        │
│  │  headers = {               │        │
│  │    key_name: key_value     │        │
│  │  }                         │        │
│  └────────────┬───────────────┘        │
│               │                        │
└───────────────┼────────────────────────┘
                │
                ▼
        ┌────────────────┐
        │ All 4 Scores:  │
        │ {              │
        │  POSITIVE: 0.8 │
        │  NEGATIVE: 0.1 │
        │  NEUTRAL:  0.08│
        │  MIXED:    0.02│
        │ }              │
        └────────────────┘
```

### 4.3 Filter Flow

```
┌──────────────────────────────────────┐
│  Filter Request                      │
│  - hash_mapping                      │
│  - classification_criteria: POSITIVE │
│  - filter_mode: ABOVE                │
│  - threshold: 0.7                    │
└──────────────┬───────────────────────┘
               │
               ▼
    ┌──────────────────────┐
    │ 1. Classify all texts│
    │    (get 4 scores each)│
    └──────┬───────────────┘
           │
           ▼
    ┌──────────────────────┐
    │ 2. Extract criterion │
    │    (e.g., POSITIVE)  │
    └──────┬───────────────┘
           │
           ▼
    ┌──────────────────────┐
    │ 3. Apply filter      │
    │    (ABOVE 0.7)       │
    └──────┬───────────────┘
           │
           ▼
    ┌──────────────────────┐
    │ 4. Return filtered   │
    │    hash list         │
    └──────────────────────┘
```

---

## 5. Schema Transformations

### 5.1 Enum Updates

**File:** `schemas/enums/Enum__Text__Classification__Criteria.py`

```python
# BEFORE
class Enum__Text__Classification__Criteria(str, Enum):
    BIAS       = 'bias'
    NEGATIVITY = 'negativity'
    POSITIVITY = 'positivity'
    URGENCY    = 'urgency'

# AFTER
class Enum__Text__Classification__Criteria(str, Enum):
    POSITIVE = 'positive'
    NEGATIVE = 'negative'
    NEUTRAL  = 'neutral'
    MIXED    = 'mixed'
```

**File:** `schemas/enums/Enum__Text__Classification__Engine_Mode.py`

```python
# BEFORE
class Enum__Text__Classification__Engine_Mode(str, Enum):
    LLM_SINGLE   = 'llm_single'
    LLM_MULTIPLE = 'llm_multiple'
    RANDOM       = 'random'
    TEXT_HASH    = 'text_hash'

# AFTER
class Enum__Text__Classification__Engine_Mode(str, Enum):
    AWS_COMPREHEND = 'aws_comprehend'
    TEXT_HASH      = 'text_hash'
    RANDOM         = 'random'
```

### 5.2 Classification Request Schema

**File:** `schemas/classification/Schema__Classification__Request.py`

```python
# BEFORE
class Schema__Classification__Request(Type_Safe):
    hash_mapping            : Dict[Safe_Str__Hash, str]
    classification_criteria : Enum__Text__Classification__Criteria  # DELETE!

# AFTER
class Schema__Classification__Request(Type_Safe):
    hash_mapping : Dict[Safe_Str__Hash, str]
    # That's it! Always returns all 4 scores
```

### 5.3 Classification Response Schema

**File:** `schemas/classification/Schema__Classification__Response.py`

```python
# BEFORE
class Schema__Classification__Response(Type_Safe):
    hash_ratings            : Dict[Safe_Str__Hash, Safe_Float__Text__Classification]  # Single score
    classification_criteria : Enum__Text__Classification__Criteria
    total_hashes            : Safe_UInt
    success                 : bool

# AFTER
class Schema__Classification__Response(Type_Safe):
    hash_ratings : Dict[Safe_Str__Hash, 
                       Dict[Enum__Text__Classification__Criteria, 
                            Safe_Float__Text__Classification]]  # All 4 scores!
    total_hashes : Safe_UInt
    success      : bool
```

**Example Response:**
```python
{
  "hash_ratings": {
    "abc1234567": {
      "positive": 0.8567,
      "negative": 0.0234,
      "neutral": 0.1123,
      "mixed": 0.0076
    }
  },
  "total_hashes": 1,
  "success": true
}
```

### 5.4 Filter Request Schema (Keep `classification_criteria`!)

**File:** `schemas/classification/Schema__Classification__Filter_Request.py`

```python
# UNCHANGED - classification_criteria STAYS for filters!
class Schema__Classification__Filter_Request(Type_Safe):
    hash_mapping            : Dict[Safe_Str__Hash, str]
    classification_criteria : Enum__Text__Classification__Criteria  # KEEP THIS!
    filter_mode             : Enum__Classification__Filter_Mode
    threshold               : Safe_Float
    threshold_max           : Optional[Safe_Float] = None
    output_mode             : Enum__Classification__Output_Mode = ...
```

**Rationale:** Filters need to know which criterion to filter by (e.g., "filter by POSITIVE > 0.7")

### 5.5 Internal Classification Schema

**File:** `schemas/Schema__Semantic_Text__Classification.py`

```python
# BEFORE
class Schema__Semantic_Text__Classification(Type_Safe):
    text                : Safe_Str__Text
    text__hash          : Safe_Str__Hash = None
    text__classification: Dict[Enum__Text__Classification__Criteria,
                               Safe_Float__Text__Classification]
    engine_mode         : Enum__Text__Classification__Engine_Mode

# AFTER - Already compatible! Just update usage to always have all 4 scores
class Schema__Semantic_Text__Classification(Type_Safe):
    text                : Safe_Str__Text
    text__hash          : Safe_Str__Hash = None
    text__classification: Dict[Enum__Text__Classification__Criteria,
                               Safe_Float__Text__Classification]  # All 4!
    engine_mode         : Enum__Text__Classification__Engine_Mode
```

---

## 6. Engine Implementation

### 6.1 Base Engine Interface

**File:** `service/semantic_text/engines/Semantic_Text__Engine.py`

```python
from typing import Dict
from osbot_utils.type_safe.Type_Safe import Type_Safe
from osbot_utils.type_safe.primitives.domains.common.safe_str.Safe_Str__Text import Safe_Str__Text

class Semantic_Text__Engine(Type_Safe):
    engine_mode: Enum__Text__Classification__Engine_Mode

    def classify_text(self, 
                      text: Safe_Str__Text
                     ) -> Dict[Enum__Text__Classification__Criteria, 
                              Safe_Float__Text__Classification]:
        """
        Classify text and return ALL 4 sentiment scores.
        
        Returns:
            {
                POSITIVE: 0.7,
                NEGATIVE: 0.1,
                NEUTRAL: 0.15,
                MIXED: 0.05
            }
        """
        raise NotImplementedError()
```

### 6.2 Hash-Based Engine (Updated)

**File:** `service/semantic_text/engines/Semantic_Text__Engine__Hash_Based.py`

```python
from hashlib import md5
from typing import Dict

class Semantic_Text__Engine__Hash_Based(Semantic_Text__Engine):
    engine_mode = Enum__Text__Classification__Engine_Mode.TEXT_HASH
    semantic_text_hashes: Semantic_Text__Hashes

    @type_safe
    def classify_text(self, text: Safe_Str__Text) -> Dict[...]:
        """Return all 4 sentiment scores using hash-based pseudo-random"""
        
        # Generate deterministic score for each criterion
        scores = {}
        for criterion in Enum__Text__Classification__Criteria:
            score = self._hash_based_classification(text, criterion)
            scores[criterion] = score
        
        # Normalize scores to sum to 1.0 (like AWS Comprehend)
        total = sum(float(s) for s in scores.values())
        normalized = {
            k: Safe_Float__Text__Classification(float(v) / total) 
            for k, v in scores.items()
        }
        
        return normalized

    def _hash_based_classification(self, 
                                   text: Safe_Str__Text,
                                   criterion: Enum__Text__Classification__Criteria
                                  ) -> Safe_Float__Text__Classification:
        """Generate deterministic score for one criterion"""
        combined = f"{text}_{criterion.value}"
        full_hash = md5(combined.encode()).hexdigest()
        hash_int = int(full_hash[:16], 16)
        rating = (hash_int % 10000) / 10000.0
        return Safe_Float__Text__Classification(rating)
```

### 6.3 Random Engine (Updated)

**File:** `service/semantic_text/engines/Semantic_Text__Engine__Random.py`

```python
from osbot_utils.utils.Misc import random_number
from typing import Dict

class Semantic_Text__Engine__Random(Semantic_Text__Engine):
    engine_mode = Enum__Text__Classification__Engine_Mode.RANDOM
    semantic_text_hashes: Semantic_Text__Hashes

    @type_safe
    def classify_text(self, text: Safe_Str__Text) -> Dict[...]:
        """Return all 4 sentiment scores using random values"""
        
        # Generate 4 random numbers
        raw_scores = [random_number(0, 100) for _ in range(4)]
        total = sum(raw_scores)
        
        # Normalize to sum to 1.0
        criteria_list = list(Enum__Text__Classification__Criteria)
        scores = {
            criteria_list[i]: Safe_Float__Text__Classification(raw_scores[i] / total)
            for i in range(4)
        }
        
        return scores
```

### 6.4 AWS Comprehend Engine (NEW)

**File:** `service/semantic_text/engines/Semantic_Text__Engine__AWS_Comprehend.py`

```python
from typing import Dict
import requests
from osbot_utils.type_safe.Type_Safe import Type_Safe
from osbot_utils.type_safe.type_safe_core.decorators.type_safe import type_safe
from osbot_utils.type_safe.primitives.domains.common.safe_str.Safe_Str__Text import Safe_Str__Text

class Semantic_Text__Engine__AWS_Comprehend(Semantic_Text__Engine):
    """
    Engine that calls AWS Comprehend Service via HTTP.
    
    Environment Variables Required:
        AUTH__SERVICE__AWS__COMPREHEND__BASE_URL
        AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME
        AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE
    """
    
    engine_mode: Enum__Text__Classification__Engine_Mode = Enum__Text__Classification__Engine_Mode.AWS_COMPREHEND
    base_url: str           # e.g., "https://api.example.com"
    api_key_name: str       # e.g., "x-api-key"
    api_key_value: str      # The actual API key value

    @type_safe
    def classify_text(self, text: Safe_Str__Text) -> Dict[Enum__Text__Classification__Criteria, 
                                                          Safe_Float__Text__Classification]:
        """
        Call AWS Comprehend service and return all 4 sentiment scores.
        
        Calls: POST {base_url}/comprehend/detect-sentiment
        
        Fail-fast on errors (no retry, no fallback).
        """
        
        url = f"{self.base_url}/comprehend/detect-sentiment"
        headers = {self.api_key_name: self.api_key_value}
        payload = {
            "text": str(text),
            "language_code": "en",
            "use_cache": False  # Ignore caching for now
        }
        
        response = requests.post(url, json=payload, headers=headers)
        
        # Fail fast on HTTP errors
        response.raise_for_status()
        
        data = response.json()
        
        # Map AWS Comprehend response to our criteria
        # AWS response: {"sentiment": "Positive", "score": {"positive": 0.9, ...}}
        aws_scores = data["score"]
        
        return {
            Enum__Text__Classification__Criteria.POSITIVE: Safe_Float__Text__Classification(aws_scores["positive"]),
            Enum__Text__Classification__Criteria.NEGATIVE: Safe_Float__Text__Classification(aws_scores["negative"]),
            Enum__Text__Classification__Criteria.NEUTRAL:  Safe_Float__Text__Classification(aws_scores["neutral"]),
            Enum__Text__Classification__Criteria.MIXED:    Safe_Float__Text__Classification(aws_scores["mixed"])
        }
```

---

## 7. Engine Factory Implementation

**File:** `service/semantic_text/Semantic_Text__Engine__Factory.py`

```python
from osbot_utils.decorators.methods.cache_on_self import cache_on_self
from osbot_utils.type_safe.Type_Safe import Type_Safe
from osbot_utils.utils.Env import get_env

class Semantic_Text__Engine__Factory(Type_Safe):
    """
    Factory for creating and caching semantic text engines.
    
    Uses @cache_on_self pattern for singleton instances.
    """
    
    @cache_on_self
    def engine__aws_comprehend(self):
        """
        Create AWS Comprehend engine (cached as singleton).
        
        Environment variables required:
            AUTH__SERVICE__AWS__COMPREHEND__BASE_URL
            AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME
            AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE
        """
        from .engines.Semantic_Text__Engine__AWS_Comprehend import Semantic_Text__Engine__AWS_Comprehend
        
        base_url      = get_env('AUTH__SERVICE__AWS__COMPREHEND__BASE_URL')
        api_key_name  = get_env('AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME')
        api_key_value = get_env('AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE')
        
        if not all([base_url, api_key_name, api_key_value]):
            raise ValueError("AWS Comprehend environment variables not configured")
        
        return Semantic_Text__Engine__AWS_Comprehend(
            base_url=base_url,
            api_key_name=api_key_name,
            api_key_value=api_key_value
        )
    
    @cache_on_self
    def engine__hash_based(self):
        """Create hash-based engine (cached as singleton)"""
        from .engines.Semantic_Text__Engine__Hash_Based import Semantic_Text__Engine__Hash_Based
        return Semantic_Text__Engine__Hash_Based()
    
    @cache_on_self  
    def engine__random(self):
        """Create random engine (cached as singleton)"""
        from .engines.Semantic_Text__Engine__Random import Semantic_Text__Engine__Random
        return Semantic_Text__Engine__Random()
    
    def get_engine(self, engine_mode: Enum__Text__Classification__Engine_Mode):
        """
        Get engine by mode (returns cached singleton).
        
        Args:
            engine_mode: One of AWS_COMPREHEND, TEXT_HASH, RANDOM
            
        Returns:
            Cached engine instance
            
        Raises:
            ValueError: If engine_mode is unknown
        """
        if engine_mode == Enum__Text__Classification__Engine_Mode.AWS_COMPREHEND:
            return self.engine__aws_comprehend()
        elif engine_mode == Enum__Text__Classification__Engine_Mode.TEXT_HASH:
            return self.engine__hash_based()
        elif engine_mode == Enum__Text__Classification__Engine_Mode.RANDOM:
            return self.engine__random()
        else:
            raise ValueError(f"Unknown engine mode: {engine_mode}")
```

---

## 8. Service Layer Updates

**File:** `service/semantic_text/Semantic_Text__Service.py`

```python
# BEFORE - Hardcoded engine
class Semantic_Text__Service(Type_Safe):
    semantic_text__engine: Semantic_Text__Engine = None

    def setup(self):
        self.semantic_text__engine = Semantic_Text__Engine__Hash_Based()  # Hardcoded!
        return self

    def classify_text(self, text, classification_criteria):
        return self.semantic_text__engine.classify_text(text, classification_criteria)


# AFTER - No longer needed! Routes call factory directly.
# Can be deleted or simplified to just factory holder.
```

**Rationale:** With engine selection in routes, the service layer becomes unnecessary. Routes interact with factory directly.

---

## 9. Route Updates

**File:** `fast_api/routes/Routes__Semantic_Classification.py`

### 9.1 Current Routes
```
POST /semantic-classification/single/rate
POST /semantic-classification/single/filter
POST /semantic-classification/multi/rate
POST /semantic-classification/multi/filter
```

### 9.2 New Routes

```
POST /semantic-classification/{engine_mode}/rate
POST /semantic-classification/{engine_mode}/filter
POST /semantic-classification/{engine_mode}/filter/multi
```

**Path Parameter:** `engine_mode` ∈ {aws_comprehend, text_hash, random}

### 9.3 Implementation

```python
from fastapi import HTTPException
from osbot_fast_api.api.routes.Fast_API__Routes import Fast_API__Routes
from osbot_utils.decorators.methods.cache_on_self import cache_on_self

TAG__ROUTES_SEMANTIC_CLASSIFICATION = 'semantic-classification'
ROUTES_PATHS__SEMANTIC_CLASSIFICATION = [
    f'/{TAG__ROUTES_SEMANTIC_CLASSIFICATION}' + '/{engine_mode}/rate',
    f'/{TAG__ROUTES_SEMANTIC_CLASSIFICATION}' + '/{engine_mode}/filter',
    f'/{TAG__ROUTES_SEMANTIC_CLASSIFICATION}' + '/{engine_mode}/filter/multi'
]

class Routes__Semantic_Classification(Fast_API__Routes):
    tag: Safe_Str__Fast_API__Route__Tag = TAG__ROUTES_SEMANTIC_CLASSIFICATION
    
    @cache_on_self
    def engine_factory(self):
        """Get singleton engine factory"""
        from mgraph_ai_service_semantic_text.service.semantic_text.Semantic_Text__Engine__Factory import Semantic_Text__Engine__Factory
        return Semantic_Text__Engine__Factory()
    
    def rate(self,
             engine_mode: Enum__Text__Classification__Engine_Mode,  # Path parameter!
             request: Schema__Classification__Request
            ) -> Schema__Classification__Response:
        """
        Rate all hashes using specified engine.
        
        Returns all 4 sentiment scores for each hash.
        """
        try:
            engine = self.engine_factory().get_engine(engine_mode)
            
            hash_ratings = {}
            for hash_key, text_value in request.hash_mapping.items():
                scores = engine.classify_text(text_value)  # Returns all 4 scores
                hash_ratings[hash_key] = scores
            
            return Schema__Classification__Response(
                hash_ratings=hash_ratings,
                total_hashes=Safe_UInt(len(request.hash_mapping)),
                success=True
            )
        
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Classification failed: {str(e)}")
    
    def filter(self,
               engine_mode: Enum__Text__Classification__Engine_Mode,  # Path parameter!
               request: Schema__Classification__Filter_Request
              ) -> Schema__Classification__Filter_Response:
        """
        Filter hashes by one criterion threshold.
        
        1. Classify all texts (get 4 scores each)
        2. Extract the specified criterion
        3. Apply filter logic
        4. Return filtered results
        """
        try:
            engine = self.engine_factory().get_engine(engine_mode)
            
            # Step 1: Classify all texts
            all_scores = {}
            for hash_key, text_value in request.hash_mapping.items():
                scores = engine.classify_text(text_value)
                all_scores[hash_key] = scores
            
            # Step 2 & 3: Filter by specified criterion
            filtered_hashes = []
            for hash_key, scores in all_scores.items():
                score = scores[request.classification_criteria]  # Extract criterion
                
                if self._matches_filter(float(score), 
                                       request.filter_mode, 
                                       float(request.threshold), 
                                       float(request.threshold_max) if request.threshold_max else None):
                    filtered_hashes.append(hash_key)
            
            # Step 4: Build response
            return self._build_filter_response(
                filtered_hashes=filtered_hashes,
                hash_mapping=request.hash_mapping,
                all_scores=all_scores,
                classification_criteria=request.classification_criteria,
                output_mode=request.output_mode,
                total_hashes=Safe_UInt(len(request.hash_mapping))
            )
        
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Filter failed: {str(e)}")
    
    def filter__multi(self,
                      engine_mode: Enum__Text__Classification__Engine_Mode,
                      request: Schema__Classification__Multi_Criteria_Filter_Request
                     ) -> Schema__Classification__Multi_Criteria_Filter_Response:
        """Filter by multiple criteria with AND/OR logic"""
        # Similar implementation...
    
    def _matches_filter(self, rating_value, filter_mode, threshold, threshold_max=None):
        """Helper to check if rating matches filter condition"""
        if filter_mode == Enum__Classification__Filter_Mode.ABOVE:
            return rating_value > threshold
        elif filter_mode == Enum__Classification__Filter_Mode.BELOW:
            return rating_value < threshold
        elif filter_mode == Enum__Classification__Filter_Mode.EQUALS:
            return abs(rating_value - threshold) < 0.001
        elif filter_mode == Enum__Classification__Filter_Mode.BETWEEN:
            if threshold_max is not None:
                return threshold < rating_value < threshold_max
        return False
    
    def _build_filter_response(self, filtered_hashes, hash_mapping, all_scores, 
                               classification_criteria, output_mode, total_hashes):
        """Helper to build filter response based on output mode"""
        filtered_with_text = None
        filtered_with_ratings = None
        
        if output_mode in [Enum__Classification__Output_Mode.HASHES_WITH_TEXT, 
                          Enum__Classification__Output_Mode.FULL_RATINGS]:
            filtered_with_text = {h: hash_mapping[h] for h in filtered_hashes if h in hash_mapping}
        
        if output_mode == Enum__Classification__Output_Mode.FULL_RATINGS:
            # Return all 4 scores for filtered hashes
            filtered_with_ratings = {h: all_scores[h] for h in filtered_hashes if h in all_scores}
        
        return Schema__Classification__Filter_Response(
            filtered_hashes=filtered_hashes,
            filtered_with_text=filtered_with_text,
            filtered_with_ratings=filtered_with_ratings,
            classification_criteria=classification_criteria,
            output_mode=output_mode,
            total_hashes=total_hashes,
            filtered_count=Safe_UInt(len(filtered_hashes)),
            success=True
        )
    
    def setup_routes(self):
        self.add_route_post(self.rate)
        self.add_route_post(self.filter)
        self.add_route_post(self.filter__multi)
```

---

## 10. Environment Variables

### 10.1 Required Variables

```bash
# AWS Comprehend Service Connection
AUTH__SERVICE__AWS__COMPREHEND__BASE_URL=https://your-aws-comprehend-service.com
AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME=x-api-key
AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE=your-secret-api-key
```

### 10.2 Usage Pattern (from AWS Comprehend QA tests)

```python
from osbot_utils.utils.Env import get_env

# Constant definitions
ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__BASE_URL  = "AUTH__SERVICE__AWS__COMPREHEND__BASE_URL"
ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME  = "AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME"
ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE = "AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE"

# Retrieve values
base_url      = get_env(ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__BASE_URL)
api_key_name  = get_env(ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_NAME)
api_key_value = get_env(ENV_NAME__AUTH__SERVICE__AWS__COMPREHEND__KEY_VALUE)
```

---

## 11. Classification Service Layer Update

**File:** `service/semantic_text/classification/Classification__Filter__Service.py`

### 11.1 Current Implementation Issues

```python
def classify_all(self, request):
    for hash_key, text_value in request.hash_mapping.items():
        classification = self.semantic_text_service.classify_text(
            text_value, 
            classification_criteria=request.classification_criteria  # Single criterion
        )
        rating = classification.text__classification.get(request.classification_criteria)
        hash_ratings[hash_key] = rating  # Single score
```

### 11.2 Updated Implementation

```python
def classify_all(self, 
                 engine_mode: Enum__Text__Classification__Engine_Mode,
                 request: Schema__Classification__Request
                ) -> Schema__Classification__Response:
    """Classify all hashes - now returns all 4 scores per hash"""
    
    engine = self.engine_factory.get_engine(engine_mode)
    
    hash_ratings = {}
    for hash_key, text_value in request.hash_mapping.items():
        scores = engine.classify_text(text_value)  # Returns all 4 scores
        hash_ratings[hash_key] = scores
    
    return Schema__Classification__Response(
        hash_ratings=hash_ratings,
        total_hashes=Safe_UInt(len(request.hash_mapping)),
        success=True
    )
```

**Key Change:** No more `classification_criteria` parameter, always return all 4 scores.

---

## 12. Testing Strategy

### 12.1 Unit Tests to Update

All tests referencing old criteria:
- `POSITIVITY` → `POSITIVE`
- `NEGATIVITY` → `NEGATIVE`
- Remove `BIAS`, `URGENCY` references

### 12.2 New Tests Required

**Test: Engine Factory**
```python
def test__engine_factory__singleton():
    factory = Semantic_Text__Engine__Factory()
    
    engine1 = factory.engine__hash_based()
    engine2 = factory.engine__hash_based()
    
    assert engine1 is engine2  # Same instance (cached)
```

**Test: AWS Comprehend Engine**
```python
def test__aws_comprehend_engine__classify_text():
    # Requires env vars set
    engine = Semantic_Text__Engine__AWS_Comprehend(...)
    
    scores = engine.classify_text("This is great!")
    
    assert len(scores) == 4
    assert all(criterion in scores for criterion in Enum__Text__Classification__Criteria)
    assert sum(float(s) for s in scores.values()) ≈ 1.0
```

**Test: Path Parameter Routing**
```python
def test__routes__engine_selection():
    response = client.post(
        "/semantic-classification/aws_comprehend/rate",
        json={"hash_mapping": {"abc": "test"}}
    )
    
    assert response.status_code == 200
    assert "hash_ratings" in response.json()
```

### 12.3 Integration Tests

Create integration test that:
1. Calls HTML service to get hashes
2. Calls Semantic Text service with different engines
3. Compares results (hash_based vs aws_comprehend)

---

## 13. Implementation Checklist

### Phase 1: Schema Updates
- [ ] Update `Enum__Text__Classification__Criteria` (4 new values)
- [ ] Update `Enum__Text__Classification__Engine_Mode` (add AWS_COMPREHEND)
- [ ] Remove `classification_criteria` from `Schema__Classification__Request`
- [ ] Update `Schema__Classification__Response` (Dict of 4 scores)
- [ ] Verify filter schemas still have `classification_criteria` (they need it!)

### Phase 2: Engine Updates
- [ ] Update `Semantic_Text__Engine` base class (remove criteria param)
- [ ] Update `Semantic_Text__Engine__Hash_Based` (return 4 scores)
- [ ] Update `Semantic_Text__Engine__Random` (return 4 scores)
- [ ] Create `Semantic_Text__Engine__AWS_Comprehend` (HTTP client)

### Phase 3: Factory Pattern
- [ ] Create `Semantic_Text__Engine__Factory`
- [ ] Implement `@cache_on_self` singleton methods
- [ ] Add environment variable loading
- [ ] Add error handling for missing env vars

### Phase 4: Route Updates
- [ ] Update route paths (add `{engine_mode}` parameter)
- [ ] Update route handlers (call factory.get_engine)
- [ ] Update `classify_all` logic (no criteria param)
- [ ] Update filter logic (extract criterion from 4 scores)
- [ ] Update OpenAPI documentation

### Phase 5: Service Cleanup
- [ ] Update or remove `Semantic_Text__Service` (may not be needed)
- [ ] Update `Classification__Filter__Service` (use factory)
- [ ] Remove hardcoded engine initialization

### Phase 6: Testing
- [ ] Update all unit tests (new criteria names)
- [ ] Add factory tests
- [ ] Add AWS Comprehend engine tests
- [ ] Add integration tests
- [ ] Test all 3 engines (aws_comprehend, text_hash, random)

### Phase 7: Documentation
- [ ] Update API docs (OpenAPI)
- [ ] Update README with engine selection examples
- [ ] Document environment variables
- [ ] Add migration guide for breaking changes

---

## 14. API Usage Examples

### 14.1 Classification (All 4 Scores)

**Request:**
```http
POST /semantic-classification/aws_comprehend/rate
Content-Type: application/json

{
  "hash_mapping": {
    "abc1234567": "This product is amazing!",
    "def7890123": "Terrible experience, very disappointed"
  }
}
```

**Response:**
```json
{
  "hash_ratings": {
    "abc1234567": {
      "positive": 0.9123,
      "negative": 0.0234,
      "neutral": 0.0576,
      "mixed": 0.0067
    },
    "def7890123": {
      "positive": 0.0134,
      "negative": 0.8976,
      "neutral": 0.0654,
      "mixed": 0.0236
    }
  },
  "total_hashes": 2,
  "success": true
}
```

### 14.2 Filter by Criterion

**Request:**
```http
POST /semantic-classification/text_hash/filter
Content-Type: application/json

{
  "hash_mapping": {
    "abc1234567": "Great!",
    "def7890123": "Terrible!"
  },
  "classification_criteria": "positive",
  "filter_mode": "above",
  "threshold": 0.7,
  "output_mode": "full-ratings"
}
```

**Response:**
```json
{
  "filtered_hashes": ["abc1234567"],
  "filtered_with_ratings": {
    "abc1234567": {
      "positive": 0.8567,
      "negative": 0.0234,
      "neutral": 0.1123,
      "mixed": 0.0076
    }
  },
  "classification_criteria": "positive",
  "output_mode": "full-ratings",
  "total_hashes": 2,
  "filtered_count": 1,
  "success": true
}
```

### 14.3 Engine Comparison

```python
# Test all 3 engines with same input
hash_mapping = {"test": "This is wonderful!"}

# Hash-based (deterministic pseudo-random)
response1 = client.post("/semantic-classification/text_hash/rate", 
                       json={"hash_mapping": hash_mapping})

# Random (different each time)
response2 = client.post("/semantic-classification/random/rate",
                       json={"hash_mapping": hash_mapping})

# AWS Comprehend (real ML)
response3 = client.post("/semantic-classification/aws_comprehend/rate",
                       json={"hash_mapping": hash_mapping})
```

---

## 15. Migration Notes

### 15.1 Breaking Changes

**This is a breaking change - no backward compatibility.**

**API Changes:**
- Classification requests no longer accept `classification_criteria`
- Classification responses always return 4 scores (not 1)
- Criteria enum values changed (POSITIVITY→POSITIVE, etc.)
- Route paths changed (added `{engine_mode}` parameter)

### 15.2 Migration Path

**Old Code:**
```python
# Request
{
  "hash_mapping": {"abc": "text"},
  "classification_criteria": "positivity"
}

# Response
{
  "hash_ratings": {"abc": 0.85},
  "classification_criteria": "positivity"
}
```

**New Code:**
```python
# Request
{
  "hash_mapping": {"abc": "text"}
  # No classification_criteria!
}

# Response
{
  "hash_ratings": {
    "abc": {
      "positive": 0.85,
      "negative": 0.05,
      "neutral": 0.08,
      "mixed": 0.02
    }
  }
}

# To get just positive score:
positive_score = response["hash_ratings"]["abc"]["positive"]
```

---

## 16. Open Questions / Future Enhancements

1. **Batch Processing:** Should we leverage AWS Comprehend's batch endpoint for multiple hashes?

2. **Caching Strategy:** Currently ignored - should we add caching layer?

3. **Error Handling:** Currently fail-fast - should we add retry logic or fallback engines?

4. **Default Engine:** Should there be a default engine if path parameter is omitted?

5. **Topic Classification:** Separate effort - not covered in this transformation

6. **Multi-criteria Filter:** How does this work with all-4-scores model? (Implementation TBD)

---

## 17. Success Criteria

✅ **Phase 1 Complete When:**
- All schemas updated and Type_Safe compliant
- Enum values match AWS Comprehend exactly

✅ **Phase 2 Complete When:**
- All 3 engines return 4 scores
- Scores sum to ~1.0 (normalized)

✅ **Phase 3 Complete When:**
- Factory pattern implemented with `@cache_on_self`
- All engines accessible via factory

✅ **Phase 4 Complete When:**
- Routes accept `{engine_mode}` path parameter
- All 3 engines callable via API

✅ **Phase 5 Complete When:**
- AWS Comprehend integration works end-to-end
- Real sentiment scores returned

✅ **Phase 6 Complete When:**
- All tests updated and passing
- Integration tests verify all engines
