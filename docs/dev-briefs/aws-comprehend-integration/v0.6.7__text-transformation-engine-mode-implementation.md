# Technical Brief: Text Transformation Engine Mode Implementation

**Document Version:** v0.6.7  
**Date:** 2025-11-17  
**Author:** Claude Sonnet 4.5 (after lengthy Architecture Design Session)

## Executive Summary

This document outlines the architectural changes required to align the `text-transformation` service with the `semantic-classification` service patterns, enabling intelligent text filtering based on sentiment analysis before applying visual transformations.

**Key Changes:**
1. Add `engine_mode` support to text transformations (AWS_COMPREHEND, TEXT_HASH, RANDOM)
2. Implement multi-criteria sentiment filtering
3. Unify route patterns with `transformation_mode` as path variable
4. Leverage existing `Classification__Filter__Service` infrastructure
5. Maintain backwards compatibility for ABCDE mode

---

## Context & Motivation

### Current State

The codebase has two separate services:

1. **Semantic Classification** (`/semantic-classification`)
   - Supports multiple engines: AWS_COMPREHEND (ML-based), TEXT_HASH (deterministic), RANDOM
   - Classifies text into 4 sentiment scores: positive, negative, neutral, mixed
   - Filters texts based on criteria and thresholds
   - Production-ready with real AWS Comprehend integration

2. **Text Transformation** (`/text-transformation`)
   - No engine mode support (always random/hash-based selection)
   - Three transformation modes: XXX_RANDOM, HASHES_RANDOM, ABCDE_BY_SIZE
   - Limited filtering capabilities

### Business Workflow

The complete pipeline for content filtering:

```
HTML Pages ‚Üí Extract Hashes ‚Üí Classify by Sentiment ‚Üí Filter by Criteria ‚Üí Transform Selected ‚Üí Reconstruct HTML
```

**Use Case Example:**
- Web page with mixed content
- Classify all text nodes using AWS Comprehend
- Hide/mask negative sentiment content (transform to "xxx")
- Show positive/neutral content normally
- Render filtered HTML to user

### The Gap

Text transformation currently lacks intelligent selection - it can't filter based on sentiment. This requires manual coordination between two separate service calls, which is inefficient and error-prone.

---

## Key Architectural Insights

### 1. AWS Comprehend Score Distribution

Real-world AWS Comprehend scores are **highly polarized**:

```python
# Positive text example:
score = {
    'positive': 0.9903,  # ‚Üê Dominant
    'negative': 0.0009,
    'neutral':  0.0078,
    'mixed':    0.0008
}

# Negative text example:
score = {
    'positive': 0.0001,
    'negative': 0.9965,  # ‚Üê Dominant
    'neutral':  0.0022,
    'mixed':    0.0009
}

# Neutral text example:
score = {
    'positive': 0.1627,
    'negative': 0.1128,
    'neutral':  0.6909,  # ‚Üê Dominant
    'mixed':    0.0335
}
```

**Implication:** One sentiment always dominates (>0.6), others are minimal (<0.3). This means:
- `BETWEEN` filter mode is rarely useful (no texts score 0.4-0.6 on multiple criteria)
- `EQUALS` filter mode is impractical (float precision issues)
- Simple `ABOVE`/`BELOW` thresholds are sufficient

**Recent Commit:** These modes have been removed:
> "breaking change: removed BETWEEN and EQUALS from Enum__Classification__Filter_Mode"

### 2. Two-Phase Transformation Operation

Text transformation should operate in two distinct phases:

**Phase 1: Classification & Selection**
- Use engine_mode (AWS_COMPREHEND | TEXT_HASH | RANDOM) to classify texts
- Apply filter criteria to select which texts qualify
- Output: List of hash IDs to transform

**Phase 2: Visual Transformation**
- Apply transformation_mode (XXX | HASHES | ABCDE) to selected texts
- Unselected texts remain unchanged
- Output: Modified hash mapping

This separation allows **intelligent selection** (Phase 1) combined with **visual transformation** (Phase 2).

### 3. Reuse Existing Infrastructure

The `semantic-classification` service already has:
- ‚úÖ `Classification__Filter__Service` - Multi-criteria filtering logic
- ‚úÖ `Semantic_Text__Engine__Factory` - Engine instantiation
- ‚úÖ `Semantic_Text__Engine__AWS_Comprehend` - Real AWS integration
- ‚úÖ `Schema__Classification__Criterion_Filter` - Filter configuration

**Decision:** Text transformation should **leverage** these existing classes rather than duplicating logic.

---

## Proposed Architecture

### High-Level Design

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Text__Transformation__Service                               ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇ Phase 1: Classification & Selection   ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ  ‚Üí Classification__Filter__Service    ‚îÇ  (REUSE!)       ‚îÇ
‚îÇ  ‚îÇ  ‚Üí Semantic_Text__Engine__Factory     ‚îÇ  (REUSE!)       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ                      ‚Üì                                      ‚îÇ
‚îÇ              [Filtered Hash List]                           ‚îÇ
‚îÇ                      ‚Üì                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇ Phase 2: Visual Transformation        ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ  ‚Üí Text__Transformation__Engine       ‚îÇ  (NEW LOGIC)    ‚îÇ
‚îÇ  ‚îÇ     - XXX_Random                      ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ     - Hashes_Random                   ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ     - ABCDE_By_Size                   ‚îÇ                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Responsibilities

**Classification__Filter__Service** (existing):
- Handles all classification logic
- Supports multi-criteria filtering
- Works with all engine modes
- Returns filtered hash lists

**Text__Transformation__Service** (updated):
- Orchestrates the two-phase process
- Calls classification service for Phase 1
- Applies visual transformations for Phase 2
- Special-cases ABCDE mode (transforms all, ignores filters)

**Transformation Engines** (modified):
- **Input:** Hash mapping + list of hashes to transform
- **Output:** Modified hash mapping
- **Logic:** Transform only selected hashes, leave others unchanged

---

## Implementation Specifications

### 1. New Enum: Engine Mode

**File:** `mgraph_ai_service_semantic_text/schemas/transformation/enums/Enum__Text__Transformation__Engine_Mode.py`

```python
from enum import Enum

class Enum__Text__Transformation__Engine_Mode(str, Enum):
    """Engine modes for text transformation (determines selection logic)"""
    RANDOM         = 'random'         # Pure random selection
    TEXT_HASH      = 'text_hash'      # Hash-based deterministic selection
    AWS_COMPREHEND = 'aws_comprehend' # AWS Comprehend ML-based sentiment selection
    LLM            = 'llm'            # LLM-based selection (future)
```

**Note:** Matches `Enum__Text__Classification__Engine_Mode` values (except LLM_SINGLE/LLM_MULTIPLE which are not needed here).

### 2. Updated Request Schema

**File:** `mgraph_ai_service_semantic_text/schemas/transformation/Schema__Text__Transformation__Request.py`

```python
from typing import List
from osbot_utils.type_safe.Type_Safe import Type_Safe
from mgraph_ai_service_semantic_text.schemas.classification.Schema__Classification__Criterion_Filter import Schema__Classification__Criterion_Filter
from mgraph_ai_service_semantic_text.schemas.classification.enums.Enum__Classification__Logic_Operator import Enum__Classification__Logic_Operator
from mgraph_ai_service_semantic_text.schemas.transformation.enums.Enum__Text__Transformation__Engine_Mode import Enum__Text__Transformation__Engine_Mode
from mgraph_ai_service_semantic_text.schemas.transformation.enums.Enum__Text__Transformation__Mode import Enum__Text__Transformation__Mode

class Schema__Text__Transformation__Request(Type_Safe):
    """Text transformation request with multi-criteria sentiment filtering"""
    
    # Core Data
    hash_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]
    
    # Phase 1: Classification & Selection (optional - if None, transform ALL)
    engine_mode: Optional[Enum__Text__Transformation__Engine_Mode] = None
    criterion_filters: Optional[List[Schema__Classification__Criterion_Filter]] = None
    logic_operator: Enum__Classification__Logic_Operator = Enum__Classification__Logic_Operator.AND
    
    # Phase 2: Transformation
    transformation_mode: Enum__Text__Transformation__Mode
```

**Key Design Decisions:**

1. **Optional Filtering:** If `engine_mode` and `criterion_filters` are `None`, transform ALL hashes (backwards compatible)

2. **Reuse Existing Schema:** `Schema__Classification__Criterion_Filter` already has:
   ```python
   class Schema__Classification__Criterion_Filter(Type_Safe):
       criterion: Enum__Text__Classification__Criteria      # positive/negative/neutral/mixed
       filter_mode: Enum__Classification__Filter_Mode       # above/below
       threshold: Safe_Float                                # 0.0-1.0
       # threshold_max removed (not needed)
   ```

3. **Multi-Criteria Support:** Enable complex filtering like "high positive AND low negative"

4. **Logic Operator:** AND/OR combination of multiple criteria

### 3. Convenience Schema for Single Criterion

**File:** `mgraph_ai_service_semantic_text/schemas/routes/Schema__Text__Transformation__Request__Convenience.py`

```python
from typing import Optional
from osbot_utils.type_safe.Type_Safe import Type_Safe

class Schema__Text__Transformation__Request__Convenience(Type_Safe):
    """Simplified request for single-criterion path parameter routes"""
    
    hash_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]
    
    # Note: engine_mode, criteria, filter_mode, threshold come from path params
    # transformation_mode also comes from path params
```

### 4. Updated Routes

**File:** `mgraph_ai_service_semantic_text/fast_api/routes/Routes__Text_Transformation.py`

```python
TAG__ROUTES_TEXT_TRANSFORMATION = 'text-transformation'

ROUTES_PATHS__TEXT_TRANSFORMATION = [
    # Generic endpoint (full multi-criteria control)
    f'/{TAG__ROUTES_TEXT_TRANSFORMATION}/transform',
    
    # Single-criterion convenience (unified pattern)
    f'/{TAG__ROUTES_TEXT_TRANSFORMATION}' + '/{engine_mode}/{transformation_mode}/{criteria}/{filter_mode}/{threshold}',
]

class Routes__Text_Transformation(Fast_API__Routes):
    tag: Safe_Str__Fast_API__Route__Tag = TAG__ROUTES_TEXT_TRANSFORMATION
    service: Text__Transformation__Service
    
    # ========================================
    # Generic Endpoint (Multi-Criteria)
    # ========================================
    
    def transform(self,
                  request: Schema__Text__Transformation__Request
             ) -> Schema__Text__Transformation__Response:
        """Transform hash mapping with multi-criteria sentiment filtering"""
        try:
            response = self.service.transform(request)
            
            if not response.success:
                raise HTTPException(status_code=500, detail=response.error_message)
            
            return response
            
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Transformation failed: {str(e)}")
    
    # ========================================
    # Convenience Endpoint (Single Criterion)
    # ========================================
    
    @route_path("/{engine_mode}/{transformation_mode}/{criteria}/{filter_mode}/{threshold}")
    def transform__convenience(self,
                              engine_mode: Enum__Text__Transformation__Engine_Mode,
                              transformation_mode: Enum__Text__Transformation__Mode,
                              criteria: Enum__Text__Classification__Criteria,
                              filter_mode: Enum__Classification__Filter_Mode,
                              threshold: Safe_Float,
                              request: Schema__Text__Transformation__Request__Convenience
                         ) -> Schema__Text__Transformation__Response:
        """Convenience endpoint for single-criterion filtering via path parameters"""
        
        # Special case: ABCDE transforms ALL (ignore engine_mode and filters)
        if transformation_mode == Enum__Text__Transformation__Mode.ABCDE_BY_SIZE:
            full_request = Schema__Text__Transformation__Request(
                hash_mapping=request.hash_mapping,
                engine_mode=None,              # Not used for ABCDE
                criterion_filters=None,        # Not used for ABCDE
                transformation_mode=transformation_mode
            )
            return self.transform(full_request)
        
        # Build single criterion filter
        criterion_filter = Schema__Classification__Criterion_Filter(
            criterion=criteria,
            filter_mode=filter_mode,
            threshold=threshold
        )
        
        # Build full request with single filter
        full_request = Schema__Text__Transformation__Request(
            hash_mapping=request.hash_mapping,
            engine_mode=engine_mode,
            criterion_filters=[criterion_filter],  # Single filter as list
            logic_operator=Enum__Classification__Logic_Operator.AND,  # Doesn't matter for single filter
            transformation_mode=transformation_mode
        )
        
        return self.transform(full_request)
    
    def setup_routes(self):
        """Register all route handlers"""
        self.add_route_post(self.transform)                  # Generic multi-criteria
        self.add_route_post(self.transform__convenience)     # Single-criterion convenience
```

**Route Examples:**

```bash
# Generic multi-criteria
POST /text-transformation/transform

# Single-criterion convenience routes (all use same handler!)
POST /text-transformation/aws_comprehend/xxx/negative/above/0.8
POST /text-transformation/text_hash/hashes/positive/below/0.3
POST /text-transformation/random/xxx/neutral/above/0.5

# ABCDE special case (ignores engine_mode and filters)
POST /text-transformation/random/abcde/positive/above/0.5  # Filters ignored
```

### 5. Updated Service Implementation

**File:** `mgraph_ai_service_semantic_text/service/text_transformation/Text__Transformation__Service.py`

```python
from typing import Dict, Set
from osbot_utils.type_safe.Type_Safe import Type_Safe
from mgraph_ai_service_semantic_text.service.semantic_text.classification.Classification__Filter__Service import Classification__Filter__Service
from mgraph_ai_service_semantic_text.schemas.classification.Schema__Classification__Multi_Criteria_Filter_Request import Schema__Classification__Multi_Criteria_Filter_Request
from mgraph_ai_service_semantic_text.schemas.classification.enums.Enum__Classification__Output_Mode import Enum__Classification__Output_Mode

class Text__Transformation__Service(Type_Safe):
    """Main orchestrator for text transformations with sentiment-based filtering"""
    
    classification_service: Classification__Filter__Service  # REUSE existing service!
    text_grouping: Text__Grouping__Service
    engine__xxx_random: Text__Transformation__Engine__XXX_Random
    engine__hashes_random: Text__Transformation__Engine__Hashes_Random
    engine__abcde_by_size: Text__Transformation__Engine__ABCDE_By_Size
    
    def transform(self, request: Schema__Text__Transformation__Request) -> Schema__Text__Transformation__Response:
        """Execute two-phase transformation: classification + visual transformation"""
        try:
            # Special case: ABCDE transforms ALL (no filtering)
            if request.transformation_mode == Enum__Text__Transformation__Mode.ABCDE_BY_SIZE:
                return self._transform_all_abcde(request)
            
            # Determine which hashes to transform
            if request.engine_mode is None or request.criterion_filters is None:
                # No filtering: transform ALL hashes
                selected_hashes = set(request.hash_mapping.keys())
            else:
                # Phase 1: Classification & Selection
                selected_hashes = self._classify_and_filter(request)
            
            # Phase 2: Visual Transformation
            transformed_mapping = self._apply_transformation(
                request.hash_mapping,
                selected_hashes,
                request.transformation_mode
            )
            
            # Build response
            total_hashes = Safe_UInt(len(request.hash_mapping))
            transformed_count = self._count_transformed_hashes(
                request.hash_mapping,
                transformed_mapping
            )
            
            return Schema__Text__Transformation__Response(
                transformed_mapping=transformed_mapping,
                transformation_mode=request.transformation_mode,
                success=True,
                total_hashes=total_hashes,
                transformed_hashes=transformed_count
            )
            
        except Exception as e:
            return Schema__Text__Transformation__Response(
                transformed_mapping=request.hash_mapping,
                transformation_mode=request.transformation_mode,
                success=False,
                total_hashes=Safe_UInt(len(request.hash_mapping)),
                transformed_hashes=Safe_UInt(0),
                error_message=f"Transformation failed: {str(e)}"
            )
    
    def _classify_and_filter(self, request: Schema__Text__Transformation__Request) -> Set[Safe_Str__Hash]:
        """Phase 1: Use classification service to filter hashes by sentiment"""
        
        # Build filter request for classification service
        filter_request = Schema__Classification__Multi_Criteria_Filter_Request(
            hash_mapping=request.hash_mapping,
            criterion_filters=request.criterion_filters,
            logic_operator=request.logic_operator,
            output_mode=Enum__Classification__Output_Mode.HASHES_ONLY  # Only need hash list
        )
        
        # Call existing classification service
        filter_response = self.classification_service.filter_by_multi_criteria(
            filter_request,
            request.engine_mode  # Pass through: aws_comprehend/text_hash/random
        )
        
        if not filter_response.success:
            raise RuntimeError("Classification filtering failed")
        
        return set(filter_response.filtered_hashes)
    
    def _apply_transformation(self,
                             hash_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text],
                             selected_hashes: Set[Safe_Str__Hash],
                             transformation_mode: Enum__Text__Transformation__Mode
                        ) -> Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]:
        """Phase 2: Apply visual transformation to selected hashes only"""
        
        engine = self._get_transformation_engine(transformation_mode)
        
        # Transform only selected hashes
        return engine.transform_selected(hash_mapping, selected_hashes)
    
    def _transform_all_abcde(self, request: Schema__Text__Transformation__Request) -> Schema__Text__Transformation__Response:
        """Special case: ABCDE transforms ALL hashes (ignores filters)"""
        
        transformed_mapping = self.engine__abcde_by_size.transform(request.hash_mapping)
        
        return Schema__Text__Transformation__Response(
            transformed_mapping=transformed_mapping,
            transformation_mode=request.transformation_mode,
            success=True,
            total_hashes=Safe_UInt(len(request.hash_mapping)),
            transformed_hashes=Safe_UInt(len(request.hash_mapping))  # All transformed
        )
    
    def _get_transformation_engine(self, mode: Enum__Text__Transformation__Mode) -> Text__Transformation__Engine:
        """Get transformation engine for visual mode"""
        engines = {
            Enum__Text__Transformation__Mode.XXX_RANDOM: self.engine__xxx_random,
            Enum__Text__Transformation__Mode.HASHES_RANDOM: self.engine__hashes_random,
            Enum__Text__Transformation__Mode.ABCDE_BY_SIZE: self.engine__abcde_by_size
        }
        
        engine = engines.get(mode)
        if not engine:
            raise ValueError(f"Unknown transformation mode: {mode}")
        
        return engine
    
    def _count_transformed_hashes(self,
                                  original_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text],
                                  transformed_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]
                             ) -> Safe_UInt:
        """Count how many hashes were actually transformed"""
        count = 0
        for hash_key, original_text in original_mapping.items():
            if hash_key in transformed_mapping and transformed_mapping[hash_key] != original_text:
                count += 1
        return Safe_UInt(count)
```

### 6. Updated Transformation Engines

**Key Change:** Engines now accept a **selected hashes set** and only transform those.

**Base Class Update:**

**File:** `mgraph_ai_service_semantic_text/service/text_transformation/engines/Text__Transformation__Engine.py`

```python
from typing import Dict, Set
from osbot_utils.type_safe.Type_Safe import Type_Safe

class Text__Transformation__Engine(Type_Safe):
    """Base class for text transformation engines"""
    
    transformation_mode: Enum__Text__Transformation__Mode
    
    def transform(self, hash_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]) -> Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]:
        """Transform ALL hashes (backwards compatible - used by ABCDE)"""
        raise NotImplementedError("Subclass must implement transform() method")
    
    def transform_selected(self,
                          hash_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text],
                          selected_hashes: Set[Safe_Str__Hash]
                     ) -> Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]:
        """Transform only selected hashes, leave others unchanged"""
        raise NotImplementedError("Subclass must implement transform_selected() method")
```

**Example Implementation (XXX_Random):**

**File:** `mgraph_ai_service_semantic_text/service/text_transformation/engines/Text__Transformation__Engine__XXX_Random.py`

```python
def transform_selected(self,
                      hash_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text],
                      selected_hashes: Set[Safe_Str__Hash]
                 ) -> Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]:
    """Transform only selected hashes with 'xxx' masking"""
    
    modified_mapping = Type_Safe__Dict(
        expected_key_type=Safe_Str__Hash,
        expected_value_type=Safe_Str__Comprehend__Text
    )
    
    for hash_key, original_text in hash_mapping.items():
        if hash_key in selected_hashes:
            # Transform this hash
            modified_mapping[hash_key] = self._mask_text(original_text)
        else:
            # Keep original
            modified_mapping[hash_key] = original_text
    
    return modified_mapping

def transform(self, hash_mapping: Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]) -> Dict[Safe_Str__Hash, Safe_Str__Comprehend__Text]:
    """Transform ALL hashes (backwards compatible)"""
    # Transform all hashes
    all_hashes = set(hash_mapping.keys())
    return self.transform_selected(hash_mapping, all_hashes)
```

**Similar updates needed for:**
- `Text__Transformation__Engine__Hashes_Random`
- `Text__Transformation__Engine__ABCDE_By_Size` (only implements `transform()`, not `transform_selected()`)

### 7. Remove Deprecated Schemas

**Files to Delete:**
- `Schema__Text__Transformation__Request__XXX_Random.py`
- `Schema__Text__Transformation__Request__Hashes_Random.py`
- `Schema__Text__Transformation__Request__ABCDE_By_Size.py`

**Reason:** Replaced by unified convenience endpoint with path parameters.

---

## API Usage Examples

### Example 1: Hide Negative Sentiment Content

```bash
POST /text-transformation/transform
Content-Type: application/json

{
  "hash_mapping": {
    "aaa1234567": "This product is amazing!",
    "bbb1234567": "Terrible customer service",
    "ccc1234567": "Standard delivery time"
  },
  "engine_mode": "aws_comprehend",
  "criterion_filters": [
    {
      "criterion": "negative",
      "filter_mode": "above",
      "threshold": 0.7
    }
  ],
  "logic_operator": "and",
  "transformation_mode": "xxx"
}

# Response:
{
  "transformed_mapping": {
    "aaa1234567": "This product is amazing!",      # Unchanged (positive)
    "bbb1234567": "xxxxxxxx xxxxxxxx xxxxxxx",     # Masked (negative > 0.7)
    "ccc1234567": "Standard delivery time"         # Unchanged (neutral)
  },
  "transformation_mode": "xxx",
  "success": true,
  "total_hashes": 3,
  "transformed_hashes": 1
}
```

### Example 2: Complex Multi-Criteria Filtering

Show only strongly positive OR neutral content:

```bash
POST /text-transformation/transform

{
  "hash_mapping": {...},
  "engine_mode": "aws_comprehend",
  "criterion_filters": [
    {
      "criterion": "positive",
      "filter_mode": "above",
      "threshold": 0.8
    },
    {
      "criterion": "neutral",
      "filter_mode": "above",
      "threshold": 0.6
    }
  ],
  "logic_operator": "or",  # Either condition matches
  "transformation_mode": "hashes"
}
```

### Example 3: Convenience Single-Criterion Endpoint

```bash
POST /text-transformation/aws_comprehend/xxx/negative/above/0.8

{
  "hash_mapping": {
    "aaa1234567": "Great product!",
    "bbb1234567": "Worst purchase ever"
  }
}

# Equivalent to multi-criteria request with single filter
```

### Example 4: ABCDE Mode (Ignores Filters)

```bash
POST /text-transformation/random/abcde/positive/above/0.5

{
  "hash_mapping": {
    "aaa1234567": "Short",
    "bbb1234567": "Medium length text",
    "ccc1234567": "Very long text content here"
  }
}

# Response: ALL texts grouped and transformed (filters ignored)
{
  "transformed_mapping": {
    "aaa1234567": "aaaaa",              # Group 'a' (shortest)
    "bbb1234567": "bbbbb bbbbbb bbbb",  # Group 'b'
    "ccc1234567": "ccc cccc cccc ccccccc cccc"  # Group 'c' (longest)
  }
}
```

### Example 5: No Filtering (Transform All)

```bash
POST /text-transformation/transform

{
  "hash_mapping": {...},
  "engine_mode": null,          # No engine
  "criterion_filters": null,    # No filters
  "transformation_mode": "xxx"
}

# Result: ALL hashes transformed (backwards compatible behavior)
```

---

## Implementation Checklist

### Phase 1: Foundation (Schema & Enums)
- [ ] Create `Enum__Text__Transformation__Engine_Mode.py`
- [ ] Update `Schema__Text__Transformation__Request.py` with engine_mode and filters
- [ ] Create `Schema__Text__Transformation__Request__Convenience.py`
- [ ] Delete deprecated mode-specific request schemas

### Phase 2: Service Layer
- [ ] Update `Text__Transformation__Service.py`:
  - [ ] Add `classification_service` dependency
  - [ ] Implement `_classify_and_filter()` method
  - [ ] Implement `_apply_transformation()` method
  - [ ] Handle ABCDE special case
  - [ ] Remove `randomness_percentage` logic

### Phase 3: Transformation Engines
- [ ] Update `Text__Transformation__Engine.py` base class:
  - [ ] Add `transform_selected()` method signature
  - [ ] Keep `transform()` for ABCDE compatibility
- [ ] Update `Text__Transformation__Engine__XXX_Random.py`:
  - [ ] Implement `transform_selected()`
  - [ ] Remove `text_selection` dependency
  - [ ] Remove `randomness_percentage` logic
- [ ] Update `Text__Transformation__Engine__Hashes_Random.py`:
  - [ ] Implement `transform_selected()`
  - [ ] Remove `text_selection` dependency
  - [ ] Remove `randomness_percentage` logic
- [ ] Update `Text__Transformation__Engine__ABCDE_By_Size.py`:
  - [ ] Keep existing `transform()` implementation
  - [ ] No `transform_selected()` needed

### Phase 4: Routes
- [ ] Update `Routes__Text_Transformation.py`:
  - [ ] Keep generic `transform()` endpoint
  - [ ] Add `transform__convenience()` endpoint with path params
  - [ ] Remove mode-specific endpoints (xxx_random, hashes_random, abcde_by_size)
  - [ ] Update `ROUTES_PATHS__TEXT_TRANSFORMATION`

### Phase 5: Cleanup
- [ ] Remove `Text__Selection__Service.py` (no longer needed)
- [ ] Update service `setup()` to inject `classification_service`
- [ ] Remove `randomness_percentage` from all remaining code
- [ ] Update tests

### Phase 6: Testing
- [ ] Test AWS_COMPREHEND engine mode
- [ ] Test TEXT_HASH engine mode
- [ ] Test RANDOM engine mode
- [ ] Test multi-criteria filtering
- [ ] Test ABCDE special case (ignores filters)
- [ ] Test backwards compatibility (no filters = transform all)
- [ ] Test convenience endpoint path parameters
- [ ] Integration tests with real AWS Comprehend

---

## Breaking Changes & Migration

### Breaking Changes

1. **Routes Changed:**
   - ‚ùå Removed: `/text-transformation/transform/xxx-random`
   - ‚ùå Removed: `/text-transformation/transform/hashes-random`
   - ‚ùå Removed: `/text-transformation/transform/abcde-by-size`
   - ‚úÖ New: `/text-transformation/{engine_mode}/{transformation_mode}/{criteria}/{filter_mode}/{threshold}`

2. **Request Schema Changed:**
   - ‚ùå Removed: `randomness_percentage` field
   - ‚úÖ Added: `engine_mode`, `criterion_filters`, `logic_operator` fields

3. **Mode-Specific Schemas Removed:**
   - ‚ùå `Schema__Text__Transformation__Request__XXX_Random`
   - ‚ùå `Schema__Text__Transformation__Request__Hashes_Random`
   - ‚ùå `Schema__Text__Transformation__Request__ABCDE_By_Size`

### Migration Guide

**Old API Call:**
```bash
POST /text-transformation/transform/xxx-random
{
  "hash_mapping": {...},
  "randomness_percentage": 0.5
}
```

**New API Call (Transform All):**
```bash
POST /text-transformation/transform
{
  "hash_mapping": {...},
  "engine_mode": null,
  "criterion_filters": null,
  "transformation_mode": "xxx"
}
```

**New API Call (With Filtering):**
```bash
POST /text-transformation/aws_comprehend/xxx/negative/above/0.7
{
  "hash_mapping": {...}
}
```

---

## Testing Strategy

### Unit Tests

**Test Classification Integration:**
```python
def test_transform_with_aws_comprehend_filtering():
    """Verify classification service is called correctly"""
    service = Text__Transformation__Service()
    
    request = Schema__Text__Transformation__Request(
        hash_mapping={"hash1": "Negative text", "hash2": "Positive text"},
        engine_mode=Enum__Text__Transformation__Engine_Mode.AWS_COMPREHEND,
        criterion_filters=[
            Schema__Classification__Criterion_Filter(
                criterion=Enum__Text__Classification__Criteria.NEGATIVE,
                filter_mode=Enum__Classification__Filter_Mode.ABOVE,
                threshold=0.7
            )
        ],
        transformation_mode=Enum__Text__Transformation__Mode.XXX_RANDOM
    )
    
    response = service.transform(request)
    
    assert response.success
    assert response.transformed_hashes == 1  # Only negative text transformed
```

**Test ABCDE Special Case:**
```python
def test_transform_abcde_ignores_filters():
    """Verify ABCDE transforms all hashes regardless of filters"""
    service = Text__Transformation__Service()
    
    request = Schema__Text__Transformation__Request(
        hash_mapping={"h1": "text", "h2": "longer text"},
        engine_mode=Enum__Text__Transformation__Engine_Mode.AWS_COMPREHEND,
        criterion_filters=[...],  # Should be ignored
        transformation_mode=Enum__Text__Transformation__Mode.ABCDE_BY_SIZE
    )
    
    response = service.transform(request)
    
    assert response.transformed_hashes == 2  # Both transformed
```

### Integration Tests

**Test Real AWS Comprehend:**
```python
def test_integration_aws_comprehend_negative_filtering():
    """End-to-end test with real AWS Comprehend service"""
    # Requires AWS credentials and Comprehend service running
    
    texts = {
        "hash1": "This is absolutely terrible!",
        "hash2": "Great product, highly recommend",
        "hash3": "Standard functionality"
    }
    
    request = Schema__Text__Transformation__Request(
        hash_mapping=texts,
        engine_mode=AWS_COMPREHEND,
        criterion_filters=[
            Schema__Classification__Criterion_Filter(
                criterion=NEGATIVE,
                filter_mode=ABOVE,
                threshold=0.8
            )
        ],
        transformation_mode=XXX_RANDOM
    )
    
    response = service.transform(request)
    
    assert response.success
    assert "xxx" in response.transformed_mapping["hash1"]  # Negative masked
    assert "xxx" not in response.transformed_mapping["hash2"]  # Positive unchanged
```

---

## Edge Cases & Special Handling

### 1. ABCDE Mode Always Transforms All

**Behavior:** ABCDE mode groups ALL texts by length, regardless of filters.

**Implementation:**
```python
if request.transformation_mode == ABCDE_BY_SIZE:
    # Ignore engine_mode and criterion_filters
    return self._transform_all_abcde(request)
```

**API Documentation:**
> "ABCDE transformation mode groups all texts by length and transforms them. Filter parameters are accepted for API consistency but are ignored."

### 2. Empty Filter List

**Behavior:** If `criterion_filters` is empty list `[]`, transform ALL (same as `None`).

```python
if request.engine_mode is None or not request.criterion_filters:
    selected_hashes = set(request.hash_mapping.keys())  # All
```

### 3. No Hashes Match Filter

**Behavior:** If filters match zero hashes, return original mapping unchanged.

```python
if not selected_hashes:
    # No hashes to transform
    return Schema__Text__Transformation__Response(
        transformed_mapping=request.hash_mapping,  # Unchanged
        transformed_hashes=0
    )
```

### 4. Classification Service Failure

**Behavior:** Propagate error with clear message.

```python
try:
    filter_response = self.classification_service.filter_by_multi_criteria(...)
except Exception as e:
    raise RuntimeError(f"Classification filtering failed: {str(e)}")
```

---

## Performance Considerations

### 1. Reuse Engine Instances

Classification engines are singletons (cached via `@cache_on_self` in `Semantic_Text__Engine__Factory`):

```python
# Good: Engine reused across requests
factory = Semantic_Text__Engine__Factory()
engine = factory.get_engine(AWS_COMPREHEND)  # Cached

# Bad: Creating new engine each time
engine = Semantic_Text__Engine__AWS_Comprehend()  # Don't do this
```

### 2. AWS Comprehend Batch Processing

The existing `Classification__Filter__Service` already uses batch processing for AWS Comprehend. No additional optimization needed.

### 3. Filter Early

Classification filtering happens **before** transformation, so only selected hashes are processed:

```
Input: 1000 hashes
‚Üì
Filter by negative > 0.8
‚Üì
Selected: 50 hashes
‚Üì
Transform only 50 hashes (not 1000!)
```

---

## Future Enhancements

### 1. LLM Engine Mode

```python
class Enum__Text__Transformation__Engine_Mode(str, Enum):
    LLM = 'llm'  # Already reserved
```

**Potential Implementation:**
- Use LLM to classify sentiment (more nuanced than AWS Comprehend)
- Support custom classification criteria beyond 4 sentiments
- Cost consideration: LLM calls are expensive

### 2. Custom Transformation Modes

Future transformation modes could include:
- `EMOJI_SENTIMENT`: Replace text with sentiment emoji (üòä/üò†/üòê)
- `SUMMARY`: Replace text with AI-generated summary
- `TRANSLATE`: Replace with translated text

### 3. Threshold Ranges

While `BETWEEN` was removed for sentiment scores, it might be useful for **length-based** filtering:

```python
# Future: Filter by text length
criterion_filters = [
    {
        "criterion": "text_length",
        "filter_mode": "between",
        "threshold": 10,
        "threshold_max": 100
    }
]
```

---

## References

### Related Files

**Schemas:**
- `mgraph_ai_service_semantic_text/schemas/classification/Schema__Classification__Criterion_Filter.py`
- `mgraph_ai_service_semantic_text/schemas/classification/enums/Enum__Classification__Filter_Mode.py`
- `mgraph_ai_service_semantic_text/schemas/classification/enums/Enum__Classification__Logic_Operator.py`

**Services:**
- `mgraph_ai_service_semantic_text/service/semantic_text/classification/Classification__Filter__Service.py`
- `mgraph_ai_service_semantic_text/service/semantic_text/engines/Semantic_Text__Engine__Factory.py`

**Engines:**
- `mgraph_ai_service_semantic_text/service/semantic_text/engines/Semantic_Text__Engine__AWS_Comprehend.py`
- `mgraph_ai_service_semantic_text/service/semantic_text/engines/Semantic_Text__Engine__Hash_Based.py`
- `mgraph_ai_service_semantic_text/service/semantic_text/engines/Semantic_Text__Engine__Random.py`

### Git Commits Referenced

**Recent Filter Mode Simplification:**
> "breaking change: removed BETWEEN and EQUALS from Enum__Classification__Filter_Mode  
> breaking change: threshold_max from multiple schemas and methods  
> this was a legacy filter mode which doesn't really apply to the real-world used of the multiple sentiment data that we now get (which is based on a normalised set of values for a text's rating of : positive, negative, neutral and mixed"

---

## Success Criteria

Implementation is complete when:

1. ‚úÖ All routes follow unified pattern with `engine_mode` and `transformation_mode` as path params
2. ‚úÖ Text transformation service leverages existing `Classification__Filter__Service`
3. ‚úÖ Multi-criteria filtering works with AND/OR logic
4. ‚úÖ AWS_COMPREHEND engine mode successfully filters by sentiment
5. ‚úÖ ABCDE mode ignores filters and transforms all texts
6. ‚úÖ All deprecated schemas removed
7. ‚úÖ `randomness_percentage` removed from codebase
8. ‚úÖ Tests pass for all engine modes
9. ‚úÖ API documentation updated
10. ‚úÖ Migration guide validated with real use cases

---

## Questions for Implementer

If unclear during implementation:

1. **Classification Service Injection:** Should `classification_service` be injected via `__init__` or auto-created by Type_Safe?
   
2. **Engine Factory Access:** Should `Text__Transformation__Service` access `Semantic_Text__Engine__Factory` directly, or should it go through `classification_service`?

3. **Error Handling:** Should classification errors return 500 status or gracefully fall back to transforming all hashes?

4. **ABCDE Documentation:** Should the OpenAPI schema explicitly mark filter params as "ignored" for ABCDE endpoints?

5. **Backwards Compatibility:** Should we keep a deprecated `/transform/xxx-random` endpoint for one release cycle with deprecation warnings?

---

## Appendix: AWS Comprehend Score Examples

Real-world score distributions from tests:

```python
# Strongly Positive Text: "Positive text"
{
    'mixed':    0.0008680016617290676,     # < 0.01
    'negative': 0.0009610106935724616,     # < 0.01
    'neutral':  0.007862226106226444,      # < 0.02
    'positive': 0.9903088212013245         # > 0.99 ‚Üê Dominant
}

# Strongly Negative Text: "Negative text"
{
    'mixed':    0.0009992261184379458,     # < 0.01
    'negative': 0.9965705871582031,        # > 0.99 ‚Üê Dominant
    'neutral':  0.0022562050726264715,     # < 0.01
    'positive': 0.0001739517174428329      # < 0.01
}

# Neutral Text: "Neutral text"
{
    'mixed':    0.03354164958000183,       # < 0.04
    'negative': 0.11283839493989944,       # < 0.2
    'neutral':  0.6909114718437195,        # > 0.69 ‚Üê Dominant
    'positive': 0.16270844638347626        # < 0.3
}
```

**Key Insight:** The dominant sentiment always scores >0.6, non-dominant scores <0.3. This makes simple `ABOVE`/`BELOW` thresholds highly effective.